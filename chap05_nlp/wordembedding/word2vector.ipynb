{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word 2 Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data File from Txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m[Mecab Morph Sentence]\u001b[0m \n",
      "[['※', '꿈', '의', '마법', '학교', '※', '0', '약', '3000', '년', '전', '에', '어느', '한', '사람', '이', '죽', '기', '전', '에', '쓴', '일기', '로', ',', '한국', '사람', '이', '봉화군', '명호', '면', '에', '있', '는', '어느', '산', '에서', '길', '을', '잃', '어', '헤매', '다가', '깊', '은', '웅덩이', '위', '에', '둥둥', '떠', '있', '는', '것', '을', '찾', '아', '발견', '한', '것', '이', '다'], ['한국', '고고학자', '들', '을', '어떻게', '해서', '웅덩이', '에', '가라앉', '지', '않', '고', '둥둥', '떠', '있', '을까', '하', '고', '연구', '해', '보', '았', '다'], ['발견', '당시', ',', '일기장', '이', '심하', '게', '부패', '되', '어', '있', '었', '음', '으로', '알아보', '기', '힘들', '었', '으나', '학자', '들', '이', '열심히', '연구', '한', '결과', '완전히', '는', '아니', '지만', '거의', '다', '복원', '이', '되', '었', '다']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open (\"./data/test.txt\", \"r\") as myfile : \n",
    "    str_buf = myfile.readlines()\n",
    "    \n",
    "mecab = Mecab('/usr/local/lib/mecab/dic/mecab-ko-dic')\n",
    "pos1 = mecab.pos(''.join(str_buf))\n",
    "# print(\"\\x1b[1;31m[Mecab POS]\\x1b[0m \\n{0}\\n\".format(pos1))\n",
    "\n",
    "pos2 = ' '.join(list(map(lambda x : '\\n' if x[1] in ['SF'] else x[0], pos1))).split('\\n')\n",
    "#print(\"\\x1b[1;31m[Mecab Sentence Splitting]\\x1b[0m \\n{0}\\n\".format(pos2))\n",
    "\n",
    "morphs = list(map(lambda x : mecab.morphs(x) , pos2))\n",
    "print(\"\\x1b[1;31m[Mecab Morph Sentence]\\x1b[0m \\n{0}\\n\".format(morphs[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Word2Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model check : Word2Vec(vocab=6488, size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(size=50, window=2, min_count=1)\n",
    "model.build_vocab(morphs)\n",
    "model.train(morphs)\n",
    "print(\"model check : {0}\".format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model done\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./model/w2v.bin\")\n",
    "print(\"Save Model done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load check : Word2Vec(vocab=6488, size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(\"./model/w2v.bin\")\n",
    "print(\"model load check : {0}\".format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if Vocab Exists\n",
    "Word2Vec 은 등록되지 않은 단어를 처리하지 못하는 문제가 있다. 때문에 NGram 을 접목한 FastText 등을 최근에는 많이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['다', '을', '이', '는', '의', '고', '에', '은', '\"', '를']\n",
      "꿈 단어는 존재\n"
     ]
    }
   ],
   "source": [
    "# See 10 vocab from head \n",
    "print(model.wv.index2word[0:10])\n",
    "\n",
    "# check if word exists on vocab list\n",
    "check_word = \"꿈\"\n",
    "print(\"{0} 단어는 존재\".format(check_word)) if check_word in model.wv.index2word else print(\"{0} 단어 존재 X\".format(check_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Vector of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31039247  0.90275842  0.4149451   0.51054734  0.0298194   0.41931769\n",
      " -0.63457191  0.19611101  0.29709095  0.38114071  0.05352852  0.49956471\n",
      "  0.05425501 -0.03787231 -0.48680586  0.70654428  0.71251023 -0.91716361\n",
      "  0.22234808  0.32603779  0.45212826  0.10457949  0.88205498  0.4359917\n",
      " -0.81338263 -0.52330077  0.31230068 -0.72272432  0.4651475   0.66333681\n",
      " -1.20829856 -0.48620829 -1.13907635  0.49880078 -0.97573209 -0.03256566\n",
      "  0.63568532 -0.41621193  0.93561596  1.33644569 -1.34148967  0.56874728\n",
      " -0.274919   -0.67818725 -0.11763556  0.5780732   1.95652068 -1.03716731\n",
      "  0.86015862  1.34492099]\n"
     ]
    }
   ],
   "source": [
    "print(model['마법'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m[금정테스트]\u001b[0m\n",
      "플로렌스/0.9935986995697021\n",
      "※/0.9897077679634094\n",
      "꿈/0.9883554577827454\n",
      "학교/0.9703297019004822\n",
      "타르/0.9646781086921692\n",
      "미드/0.9634619355201721\n",
      "실베스터/0.9584909677505493\n",
      "가루/0.9442243576049805\n",
      "학년/0.9385878443717957\n",
      "학생/0.9374812841415405\n",
      "\n",
      "\u001b[1;31m[부정테스트]\u001b[0m\n",
      "가르쳤/0.6605061292648315\n",
      "권유/0.6238329410552979\n",
      "홍보/0.6035796403884888\n",
      "……/0.6017792224884033\n",
      "닥쳤/0.5352236032485962\n",
      "물수/0.46747368574142456\n",
      "체취/0.4294404983520508\n",
      "기다려라/0.4236688017845154\n",
      "퍽퍽/0.41962382197380066\n",
      "새겨져/0.3585354685783386\n",
      "\n",
      "\u001b[1;31m[혼합테스트]\u001b[0m\n",
      "아양/0.9274868965148926\n",
      "공군/0.9211603403091431\n",
      "아/0.912663996219635\n",
      "옮겼/0.9113738536834717\n",
      "시각/0.905815839767456\n",
      "건의/0.9055241346359253\n",
      "들이/0.9042036533355713\n",
      "일어난/0.9035966992378235\n",
      "포상/0.9031229019165039\n",
      "밖/0.9029484987258911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = model.most_similar(positive='마법', negative='', topn=10)\n",
    "print(\"\\x1b[1;31m[금정테스트]\\x1b[0m\")\n",
    "print('\\n'.join(list(map(lambda x : str(x[0]) + '/' + str(x[1]), result1))) + '\\n')\n",
    "\n",
    "result2 = model.most_similar(positive='', negative='마법', topn=10)\n",
    "print(\"\\x1b[1;31m[부정테스트]\\x1b[0m\")\n",
    "print('\\n'.join(list(map(lambda x : str(x[0]) + '/' + str(x[1]), result2))) + '\\n')\n",
    "\n",
    "result2 = model.most_similar(positive='주인공', negative='마법', topn=10)\n",
    "print(\"\\x1b[1;31m[혼합테스트]\\x1b[0m\")\n",
    "print('\\n'.join(list(map(lambda x : str(x[0]) + '/' + str(x[1]), result2))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
