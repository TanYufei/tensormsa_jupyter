{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.image import imread, imsave \n",
    "import matplotlib.pyplot as plt  \n",
    "print(\"load done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define preprocess func\n"
     ]
    }
   ],
   "source": [
    "def change (x) :\n",
    "    dummy = [0.0, 0.0, 0.0]\n",
    "    idx = ['Clear', 'Rain', 'Clouds']\n",
    "    dummy[idx.index(x)] = 1.0\n",
    "    return dummy\n",
    "\n",
    "def to_matrix(data) :\n",
    "    return_arr = []\n",
    "    idxs = ['humidity', 'pressure', 'grnd_level', 'temp_max', 'temp', 'temp_min', 'temp_kf', 'sea_level']\n",
    "    for idx in idxs : \n",
    "        return_arr.append(float(data.get(idx)))\n",
    "    return return_arr \n",
    "\n",
    "print(\"define preprocess func\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define data get func\n"
     ]
    }
   ],
   "source": [
    "def get_test_data() :\n",
    "    resp = requests.get('http://openweathermap.org/data/2.5/forecast?q=London,us&mode=json&appid=b1b15e88fa797225412429c1c50c122a1')\n",
    "    data = resp.json()\n",
    "\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    # parse json\n",
    "    data_list = data['list']\n",
    "    for raw in data_list :\n",
    "        x_data.append(raw['main'])\n",
    "        y_data.append(raw['weather'][0]['main'])\n",
    "\n",
    "    # divide train & test\n",
    "    data_train, data_test, labels_train, labels_test = train_test_split(x_data, y_data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    # preprocess data\n",
    "    labels_train = list(map(lambda x : change(x), labels_train ))\n",
    "    labels_test = list(map(lambda x : change(x), labels_test ))\n",
    "    data_filter_train = list(map(lambda x : to_matrix(x), data_train ))\n",
    "    data_filter_test = list(map(lambda x : to_matrix(x), data_test ))\n",
    "    \n",
    "    # Print Data \n",
    "    print(\"data_test : {0}\".format(data_filter_test))\n",
    "    print(\"data_train : {0}\".format(len(data_filter_train)))\n",
    "    print(\"labels_train : {0}\".format(len(labels_train)))\n",
    "    print(\"data_test : {0}\".format(len(data_filter_test)))\n",
    "    print(\"labels_test : {0}\".format(len(labels_test)))\n",
    "\n",
    "    return np.array(labels_train), np.array(labels_test), np.array(data_filter_train), np.array(data_filter_test)\n",
    "\n",
    "print(\"define data get func\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define cnn graph func\n"
     ]
    }
   ],
   "source": [
    "def create_graph(train=True):\n",
    "\n",
    "    # placeholder is used for feeding data.\n",
    "    x = tf.placeholder(\"float\", shape=[None, 8], name = 'x') # none represents variable length of dimension. 784 is the dimension of MNIST data.\n",
    "    y_target = tf.placeholder(\"float\", shape=[None, 3], name = 'y_target') # shape argument is optional, but this is useful to debug.\n",
    "\n",
    "    # reshape input data\n",
    "    x_image = tf.reshape(x, [-1,2,4,1], name=\"x_image\")\n",
    "    \n",
    "    # Build a convolutional layer and maxpooling with random initialization\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal([2, 2, 1, 32], stddev=0.1), name=\"W_conv1\") # W is [row, col, channel, feature]\n",
    "    b_conv1 = tf.Variable(tf.zeros([32]), name=\"b_conv1\")\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1, name=\"h_conv1\")\n",
    "    h_pool1 = tf.nn.max_pool( h_conv1 , ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name = \"h_pool1\")\n",
    "    \n",
    "    # Build a fully connected layer\n",
    "    h_pool2_flat = tf.reshape(h_pool1, [-1, 1*2*32], name=\"h_pool2_flat\")\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal([1*2*32, 256], stddev=0.1), name = 'W_fc1')\n",
    "    b_fc1 = tf.Variable(tf.zeros([256]), name = 'b_fc1')\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name=\"h_fc1\")\n",
    "    \n",
    "    keep_prob = 1.0\n",
    "    if(train) : \n",
    "        # Dropout Layer\n",
    "        keep_prob = tf.placeholder(\"float\", name=\"keep_prob\")\n",
    "        h_fc1 = tf.nn.dropout(h_fc1, keep_prob, name=\"h_fc1_drop\")\n",
    "    \n",
    "    # Build a fully connected layer with softmax \n",
    "    W_fc2 = tf.Variable(tf.truncated_normal([256, 3], stddev=0.1), name = 'W_fc2')\n",
    "    b_fc2 = tf.Variable(tf.zeros([3]), name = 'b_fc2')\n",
    "    y=tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2, name=\"y\")\n",
    "    \n",
    "    # define the Loss function\n",
    "    #cross_entropy = -tf.reduce_sum(y_target*tf.log(y), name = 'cross_entropy')\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_target))\n",
    "    \n",
    "    # define optimization algorithm\n",
    "    #train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_target, 1))\n",
    "    # correct_prediction is list of boolean which is the result of comparing(model prediction , data)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) \n",
    "    # tf.cast() : changes true -> 1 / false -> 0\n",
    "    # tf.reduce_mean() : calculate the mean\n",
    "    \n",
    "    # create summary of parameters\n",
    "    tf.summary.histogram('weights_1', W_conv1)\n",
    "    tf.summary.histogram('y', y)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    merged = tf.summary.merge_all()\n",
    "    summary_writer = tf.summary.FileWriter(\"/tmp/cnn\")\n",
    "    \n",
    "    return accuracy, x, y_target, keep_prob, train_step, merged, y, cross_entropy, summary_writer, W_conv1\n",
    "    \n",
    "print(\"define cnn graph func\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Hidden Layer Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_layer(weight_list) :\n",
    "#     img = imread('/home/ubuntu/imgtest/wizard.png')\n",
    "#     print(type(img))\n",
    "#     test = np.zeros(shape=(10, 10))\n",
    "#     imsave('/home/ubuntu/imgtest/test.png', test)\n",
    "#     test = imread('/home/ubuntu/imgtest/test.png')\n",
    "    \n",
    "    for matrix in weight_list[0] :  \n",
    "        print(plt.imshow(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_test : [[61.0, 1003.97, 1003.97, 23.27, 23.27, 23.27, 0.0, 1019.82], [95.0, 1004.21, 1004.21, 12.75, 12.75, 12.75, 0.0, 1020.14], [90.0, 999.43, 999.43, 20.7, 20.7, 20.7, 0.0, 1015.17], [72.0, 1008.43, 1008.43, 17.98, 17.98, 17.98, 0.0, 1024.3], [66.0, 1011.79, 1011.79, 26.18, 26.18, 26.18, 0.0, 1027.78], [49.0, 1008.35, 1008.35, 24.5, 24.5, 24.5, 0.0, 1024.22], [78.0, 1001.37, 1001.37, 17.08, 17.08, 17.08, 0.0, 1017.23], [47.0, 1007.57, 1007.57, 24.93, 24.93, 24.93, 0.0, 1023.31]]\n",
      "data_train : 29\n",
      "labels_train : 29\n",
      "data_test : 8\n",
      "labels_test : 8\n",
      "WARNING:tensorflow:From <ipython-input-6-63d68b5038f2>:12: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "step 0, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 10, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 20, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 30, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 40, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 50, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 60, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 70, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 80, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "step 90, training accuracy: 0.276\n",
      "summary for tensorboard written\n",
      "test accuracy: 0.375\n",
      "AxesImage(54,36;334.8x223.2)\n",
      "AxesImage(54,36;334.8x223.2)\n",
      "model saved\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAA7CAYAAAAXZtIzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRIGtadpNSLsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa5dbf933c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run() : \n",
    "    try : \n",
    "        # get Data \n",
    "        labels_train, labels_test, data_filter_train, data_filter_test = get_test_data()\n",
    "        # reset Graph\n",
    "        tf.reset_default_graph()   \n",
    "        # Create Session\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))  \n",
    "        # create graph\n",
    "        accuracy, x, y_target, keep_prob, train_step, merged, y, cross_entropy, summary_writer, W_conv1 = create_graph(train=True)\n",
    "        # set saver\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        # initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        # training the MLP\n",
    "        for i in range(100): \n",
    "            sess.run(train_step, feed_dict={x: data_filter_train, y_target: labels_train, keep_prob: 0.5})\n",
    "            if i%10 == 0:\n",
    "                train_accuracy = sess.run(accuracy, feed_dict={x:data_filter_train, y_target: labels_train, keep_prob: 1})\n",
    "                print (\"step %d, training accuracy: %.3f\"%(i, train_accuracy))\n",
    "                \n",
    "                # calculate the summary and write.\n",
    "                summary = sess.run(merged, feed_dict={x:data_filter_train, y_target: labels_train, keep_prob: 1})\n",
    "                summary_writer.add_summary(summary , i)\n",
    "                print(\"summary for tensorboard written\")\n",
    "                \n",
    "        # for given x, y_target data set\n",
    "        print  (\"test accuracy: %g\"% sess.run(accuracy, feed_dict={x:data_filter_test, y_target: labels_test, keep_prob: 1}))\n",
    "        \n",
    "        # show weight matrix as image \n",
    "        weight_vectors = sess.run(W_conv1, feed_dict={x: data_filter_train, y_target: labels_train, keep_prob: 1.0})\n",
    "        show_layer(weight_vectors)\n",
    "        \n",
    "        # Save Model\n",
    "        path = './model/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            print(\"path created\")\n",
    "        saver.save(sess, path)\n",
    "        print(\"model saved\")\n",
    "    except Exception as e : \n",
    "        raise Exception (\"error on training: {0}\".format(e))\n",
    "    finally :\n",
    "        sess.close()\n",
    "\n",
    "# run stuff\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/\n",
      "model restored\n",
      "input data : [63.0, 1017.55, 1017.55, 24.05, 24.05, 24.05, 0.0, 1033.55]\n",
      "result : [array([[ 0.,  1.,  0.]], dtype=float32)]\n",
      "result : 1\n"
     ]
    }
   ],
   "source": [
    "def predict(test_data) : \n",
    "    try : \n",
    "        # reset Graph\n",
    "        tf.reset_default_graph()   \n",
    "        # Create Session\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))  \n",
    "        # create graph\n",
    "        _, x, _, _, _, _, y, _, _, _ = create_graph(train=False)\n",
    "        \n",
    "        # initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # set saver\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # Restore Model\n",
    "        path = './model/'\n",
    "        if os.path.exists(path):\n",
    "            saver.restore(sess, path)\n",
    "            print(\"model restored\")\n",
    "\n",
    "        # training the MLP\n",
    "        print(\"input data : {0}\".format(test_data))\n",
    "        y = sess.run([y], feed_dict={x: np.array([test_data])})\n",
    "        print(\"result : {0}\".format(y))\n",
    "        print(\"result : {0}\".format(np.argmax(y)))\n",
    "        \n",
    "    except Exception as e : \n",
    "        raise Exception (\"error on training: {0}\".format(e))\n",
    "    finally :\n",
    "        sess.close()\n",
    "\n",
    "# run stuff\n",
    "predict([63.0, 1017.55, 1017.55, 24.05, 24.05, 24.05, 0.0, 1033.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
