{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Vector를 통한 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕', '만나', '서', '반가워', '넌', '누구', '니', '나', '는', 'AI', '봇', '이', '란다', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "qna_data = [\n",
    "                ['안녕', '만나서 반가워']\n",
    "                ,['넌누구니', '나는 AI 봇이란다.']\n",
    "#                 ,['피자 주문 할께', '페파로니 주문해줘']\n",
    "#                ,['음료는 멀로', '콜라로 해줘']\n",
    "            ]\n",
    "mecab = Mecab('/usr/local/lib/mecab/dic/mecab-ko-dic')\n",
    "\n",
    "train_data = list(map(lambda x : mecab.morphs(' '.join(x)) , qna_data))\n",
    "\n",
    "import itertools\n",
    "train_data = list(itertools.chain.from_iterable(train_data))\n",
    "#train_data = list(set(train_data))\n",
    "\n",
    "print(list(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "bucket = np.zeros(len(train_data), dtype=np.float)\n",
    "\n",
    "for word in train_data :\n",
    "    bucket_temp = bucket.copy()\n",
    "    np.put(bucket_temp, train_data.index(word), 1)\n",
    "    print(bucket_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word to Vector (By Gensim)\n",
    "### W2V를 통해 출력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['안녕', '만나', '서', '반가워', '넌', '누구', '니', '나', '는', 'AI', '봇', '이', '란다', '.']]\n",
      "model check : Word2Vec(vocab=14, size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "train_data = [train_data]\n",
    "print(train_data)\n",
    "\n",
    "model = word2vec.Word2Vec(size=50, window=2, min_count=1)\n",
    "model.build_vocab(train_data)\n",
    "model.train(train_data)\n",
    "print(\"model check : {0}\".format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load check : Word2Vec(vocab=14, size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "file_path = './model'\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "model.save(file_path + \"/w2v.bin\")\n",
    "model = word2vec.Word2Vec.load(\"./model/w2v.bin\")\n",
    "print(\"model load check : {0}\".format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['넌', '안녕', '니', '반가워', '란다', '나', '는', '서', '봇', '누구', 'AI', '만나', '이', '.']\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 안녕, AI등 값의 Vector값 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00906392  0.00662671 -0.00857101  0.00127208  0.00892127  0.00774612\n",
      "  0.00918776  0.00846652 -0.0029425  -0.00767829 -0.00302397  0.00048057\n",
      " -0.00385544 -0.00359789 -0.00413739 -0.00219288 -0.00013363  0.00810544\n",
      "  0.00272209 -0.00583092 -0.00993142  0.00107607  0.00708261  0.00720571\n",
      " -0.00511372  0.00288195 -0.00772363  0.00142288  0.00294792 -0.00210383\n",
      "  0.00157649  0.00214393 -0.00589636  0.00866197 -0.00011011  0.00509825\n",
      " -0.00366211 -0.00307068  0.00051911 -0.00247017 -0.00681107 -0.00360943\n",
      "  0.00397343 -0.00119501 -0.00985976  0.00707069  0.0087037  -0.00117793\n",
      " -0.00323435 -0.00720304]\n"
     ]
    }
   ],
   "source": [
    "print(model['안녕'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00625702 -0.00240439  0.00722755 -0.00785832 -0.0044202  -0.0055006\n",
      " -0.00706359  0.00403029  0.00310217 -0.00281276 -0.00457072  0.00547957\n",
      " -0.00951945  0.00758849  0.00087858  0.00763961 -0.00636545 -0.00736459\n",
      "  0.00201024 -0.00974274 -0.00481566 -0.00258274 -0.00668924 -0.00819318\n",
      " -0.00582225 -0.00011333 -0.00600814 -0.0022568   0.00999346 -0.00148616\n",
      " -0.00932303 -0.0006933   0.00017863 -0.00696899  0.00237124 -0.0024723\n",
      " -0.00909115  0.00325816 -0.00215428 -0.00141546 -0.00658541 -0.00152294\n",
      "  0.00605505 -0.00082731  0.00141879 -0.00180908  0.00013175  0.00364501\n",
      "  0.00332046  0.0029849 ]\n"
     ]
    }
   ],
   "source": [
    "print(model['AI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('서', 0.3277257978916168), ('넌', 0.32181084156036377), ('란다', 0.12879055738449097), ('.', 0.04148875176906586), ('안녕', 0.026515774428844452), ('니', 0.011996626853942871), ('는', -0.01740662008523941), ('봇', -0.039780400693416595), ('반가워', -0.07147873938083649), ('이', -0.12071488797664642)]\n"
     ]
    }
   ],
   "source": [
    "result1 = model.most_similar(positive='나', negative='', topn=10)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-89d8dc509b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m font_name = matplotlib.font_manager.FontProperties(\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\u001b[0m  \u001b[0;31m# 한글 폰트 위치를 넣어주세요\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             ).get_name()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "font_name = matplotlib.font_manager.FontProperties(\n",
    "                fname=\"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"  # 한글 폰트 위치를 넣어주세요\n",
    "            ).get_name()\n",
    "vocab = model.wv.index2word\n",
    "matplotlib.rc('font', family=font_name)\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X) #t-분포 확률적 임베딩(t-SNE)은 데이터의 차원 축소에 사용\n",
    "df = pd.concat([pd.DataFrame(X_tsne),\n",
    "                pd.Series(vocab)],\n",
    "               axis=1)\n",
    "\n",
    "df.columns = ['x', 'y', 'word']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "print(df)\n",
    "ax.scatter(df['x'], df['y'])\n",
    "ax.set_xlim(df['x'].max(), df['x'].min())\n",
    "ax.set_ylim(df['y'].max(), df['y'].min())\n",
    "for i, txt in enumerate(df['word']):\n",
    "    ax.annotate(txt, (df['x'].iloc[i], df['y'].iloc[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
