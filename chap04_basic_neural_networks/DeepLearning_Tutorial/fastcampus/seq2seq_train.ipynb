{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, GRUCell, MultiRNNCell\n",
    "from tensorflow.contrib.rnn.python.ops.rnn_cell import _linear\n",
    "\n",
    "from lib import data_utils, model_utils\n",
    "from configs import model_config\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def __init__(self, config, use_lstm=True, forward_only=False,  attention=False ,sess=None):\n",
    "\n",
    "config = model_config.Config()\n",
    "use_lstm=True \n",
    "forward_only=False\n",
    "attention=True\n",
    "\n",
    "#config에서 모델의 설정값을 가져옵니다.\n",
    "vocab_size = config.vocab_size\n",
    "enc_hidden_size = config.enc_hidden_size\n",
    "enc_num_layers = config.enc_num_layers\n",
    "dec_hidden_size = config.dec_hidden_size\n",
    "dec_num_layers = config.dec_num_layers\n",
    "batch_size = config.batch_size\n",
    "attention = attention\n",
    "\n",
    "\n",
    "#학습 과정에서 가변 learning_rate 를 적용하기 위해서 tf.Variable 타입으로 선언합니다\n",
    "learning_rate = tf.Variable(float(config.learning_rate), trainable=False)\n",
    "#아래 op는 learning step 에서 두번이상 loss 가 증가헀을경우 learning_rate_decay_factor 를 곱해서\n",
    "#기본값인 learning_rate_decay_factor = 0.99의 경우 본 op가 한번 실행될때마다 learning_rate 가 1% 감소시키는 효과를 가저옵니다\n",
    "learning_rate_decay_op = learning_rate.assign(\n",
    "    learning_rate * config.learning_rate_decay_factor)\n",
    "#global_step 역시 학습 과정에서 계속 증가하여야 하는 값이므로 tf.Variable 형태로 선언하고 0으로 초기화합니다\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "max_gradient_norm = config.max_gradient_norm\n",
    "buckets = config.buckets\n",
    "\n",
    "#RNN의 내부 구조를 LSTM과 GRU중 선택으로 분기합니다.\n",
    "if use_lstm:\n",
    "    single_cell1 = LSTMCell(enc_hidden_size)\n",
    "    single_cell2 = LSTMCell(dec_hidden_size)\n",
    "else:\n",
    "    single_cell1 = GRUCell(enc_hidden_size)\n",
    "    single_cell2 = GRUCell(dec_hidden_size)\n",
    "\n",
    "#multi layers 구조의 RNN 처리를 위한 부분 입니다. tensor 1.0 ~ 1.1 구간에서 해당 구현에 대한 이슈가 존재하여 본 예제에서는\n",
    "#single layers의 구현을 가정하고 진행하겠습니다.\n",
    "#seq2seq 모델의 경우 2 layers 부터 학습이 매우 어려워지는 경향을 보이며 4 layers 이상은 학습이 거의 되지 않는다 라는 경험적인 의견이 많습니다.\n",
    "enc_cell = MultiRNNCell([single_cell1 for _ in range(enc_num_layers)])\n",
    "dec_cell = MultiRNNCell([single_cell2 for _ in range(dec_num_layers)])\n",
    "\n",
    "#인코딩 셀과 디코딩 셀을 self로 클래스 변수로 잡아 클래스내 다른 함수에서 이를 사용할것 입니다.\n",
    "encoder_cell = enc_cell\n",
    "decoder_cell = dec_cell\n",
    "\n",
    "#실제 모델의 그래프를 생성합니다.\n",
    "#_make_graph(forward_only)\n",
    "\n",
    "#tensor sever를 정의하여 모델의 학습 과정에서 파라메터과 모델구조를 저장할 수 있도록 합니다.\n",
    "#saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def _init_data(self):\n",
    "# encoder_inputs의 placeholder로 들어오는 2차원 matrix 예시 입니다.\n",
    "#[\n",
    "# [36, 6, 36, 6, 14, 5, 13, 35, 739, 41, 24, 103, EOS_ID],\n",
    "# [3, 5, 13, 956, 3, 227, EOS_ID, GO_ID, 142, 331, 4, 17, 8, 112, 6, 155, 3, EOS_ID] , ...\n",
    "#]\n",
    "\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name=\"encoder_inputs\")\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name=\"encoder_inputs_length\")\n",
    "\n",
    "# decoder_inputs의 placeholder로 들어오는 2차원 matrix 예시 입니다.\n",
    "#[\n",
    "# [GO_ID, 5, 15, 33, 12, 2021, 3,2274,EOS_ID],\n",
    "# [GO_ID, 142, 331, 4, 17, 8, 112, 6, 155, 3, EOS_ID] , ...\n",
    "#]\n",
    "\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name=\"decoder_inputs\")\n",
    "decoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name=\"decoder_inputs_length\")\n",
    "\n",
    "#np.array 타입의 슬라이싱을 이용하여 decoder_inputs의 GO 심볼이 위치하는 부분을 제거합니다\n",
    "decoder_targets = decoder_inputs[1:, :]\n",
    "\n",
    "#input 과 output 데이터를 버킷에 사이즈에 맞춰서 잘라냅니다\n",
    "#기본값은 \tmodel.config = buckets = [(8, 15)]로 이 경우에는 input의 경우 순서열의 최대 길이가 8 output의 경우 최대길이가 15로 잘리게 됩니다\n",
    "temp_encoder_inputs = encoder_inputs[:buckets[-1][0], :]\n",
    "encoder_inputs2 = temp_encoder_inputs\n",
    "temp_decoder_inputs = decoder_inputs[:buckets[-1][1], :]\n",
    "decoder_inputs2 = temp_decoder_inputs\n",
    "\n",
    "# cross entropy 계산을 위해서 decoder_input 패딩된 데이터와 실제 데이터를 골라내기 위한 mask 입니다.\n",
    "# getbatch 에서 받은 데이터를 주입할 placeholder\n",
    "target_weights = tf.placeholder(shape=(None, None), dtype=tf.float32, name=\"target_weights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_init\n",
    "\n",
    "seq2seq 모델에서 입력값과 출력값(예측값)을 담당하는 encoder와 decoder의 데이터 파이프라인을 정의합니다.\n",
    "placeholder 라는 구조는 lazy 하게 모델을 구성하고 차후에 데이터가 입력될 구조를 정의 합니다.\n",
    "\n",
    "![](http://i.imgur.com/Cc22Moi.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"embedding\") as scope:\n",
    "    #vocab_size * hidden_size 만큼의 크기를 가진 embedding_matrix를 생성 합니다.    \n",
    "    enc_embedding_matrix = tf.get_variable(\n",
    "        name=\"enc_embedding_matrix\",\n",
    "        shape=[vocab_size, enc_hidden_size],\n",
    "        initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        dtype=tf.float32)\n",
    "\n",
    "    dec_embedding_matrix = tf.get_variable(\n",
    "        name=\"dec_embedding_matrix\",\n",
    "        shape=[vocab_size, dec_hidden_size],\n",
    "        initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        dtype=tf.float32)\n",
    "\n",
    "    # 연속된 단어의 index값으로 표현된 입력값을 각 인덱스의 one-hot으로 표현하고 이어서\n",
    "    # embedding_vector화 하는 과정을 embedding_lookup을 통해서 쉽게 처리할 수 있습니다.\n",
    "\n",
    "    encoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "        enc_embedding_matrix, encoder_inputs2)\n",
    "\n",
    "    decoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "        dec_embedding_matrix, decoder_inputs2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## init_embeddings\n",
    "one-hot으로 표현된 단어 index를 hidden size * hidden_size 사이즈 만큼의 embedding vector로 생성 합니다.\n",
    "\n",
    "![](http://i.imgur.com/ZOj61li.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"encoder\") as scope:\n",
    "    # encoder_cell을 가지고 dynamic_rnn Layer를 생성하고\n",
    "    # embedding_lookup 통해서 만든 embedding_matrix를 연결합니다.\n",
    "    (encoder_outputs, encoder_state) = tf.nn.dynamic_rnn(cell=encoder_cell,\n",
    "                                                                inputs=encoder_inputs_embedded,\n",
    "                                                                sequence_length=encoder_inputs_length,\n",
    "                                                                time_major=True, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init_encoder\n",
    "\n",
    "encoder_cell을 가지고 dynamic_rnn을 통해서 Encoder 구조를 정의 합니다.\n",
    "\n",
    "![](http://i.imgur.com/AhmowtE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def _init_decoder(self, forward_only):\n",
    "with tf.variable_scope(\"decoder\") as scope:\n",
    "    def output_fn(outputs):\n",
    "        return tf.contrib.layers.linear(outputs, vocab_size, scope=scope)\n",
    "\n",
    "    # attention_states: size [batch_size, max_time, num_units]\n",
    "    attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "\n",
    "    #encoder_outputs 을 가지고 attention network에 필요한 값을 생성합니다.\n",
    "    (attention_keys, attention_values, attention_score_fn, attention_construct_fn) = (\n",
    "        seq2seq.prepare_attention(\n",
    "            attention_states=attention_states,\n",
    "            attention_option=\"bahdanau\",\n",
    "            num_units=dec_hidden_size))\n",
    "\n",
    "    #prediction 전용 모델인경우\n",
    "    if forward_only:\n",
    "        #decoder 함수로 inference를 사용하고\n",
    "        #아래의 train 과정보다 더 많은 인자를 입력 받는데\n",
    "        #전처리 과정에서 진행한 embedding 과정의 역순을 일부 자동으로 처리하기 위함입니다.\n",
    "        decoder_fn = seq2seq.attention_decoder_fn_inference(\n",
    "            output_fn=output_fn,\n",
    "            encoder_state=encoder_state,\n",
    "            attention_keys=attention_keys,\n",
    "            attention_values=attention_values,\n",
    "            attention_score_fn=attention_score_fn,\n",
    "            attention_construct_fn=attention_construct_fn,\n",
    "            embeddings=dec_embedding_matrix,\n",
    "            start_of_sequence_id=model_config.GO_ID,\n",
    "            end_of_sequence_id=model_config.EOS_ID,\n",
    "            maximum_length=buckets[-1][1],\n",
    "            num_decoder_symbols=vocab_size,\n",
    "        )\n",
    "        # rnn_decoder Layer를 생성합니다\n",
    "        # encoder를 지나서 계산된 c는 decoder_fn의 인자를 통해 decoder에 연결되고\n",
    "        # decoder_outputs에서 logit 형태로 예측값을 출력합니다.\n",
    "        (decoder_outputs, decoder_state, decoder_context_state) = (\n",
    "            seq2seq.dynamic_rnn_decoder(\n",
    "                cell=decoder_cell,\n",
    "                decoder_fn=decoder_fn,\n",
    "                time_major=True,\n",
    "                scope=scope,\n",
    "            ))\n",
    "    #train 모델인경우\n",
    "    else:\n",
    "        #decoder 함수로 train을 사용하고\n",
    "        #이전 레이어의 출력값인 encoder_state와 함께 attention 구현에 필요한 값을 입력합니다.\n",
    "        decoder_fn = seq2seq.attention_decoder_fn_train(\n",
    "            encoder_state=encoder_state,\n",
    "            attention_keys=attention_keys,\n",
    "            attention_values=attention_values,\n",
    "            attention_score_fn=attention_score_fn,\n",
    "            attention_construct_fn=attention_construct_fn,\n",
    "            name='attention_decoder'\n",
    "        )\n",
    "        # rnn_decoder Layer를 생성합니다\n",
    "        # encoder를 지나서 계산된 encoder_state는 decoder_fn을 인자를 통해 decoder에 연결되고\n",
    "        # loos값을 계산하기 위해서 decoder_outputs을 출력합니다.\n",
    "        (decoder_outputs, decoder_state, decoder_context_state) = (\n",
    "            seq2seq.dynamic_rnn_decoder(\n",
    "                cell=decoder_cell,\n",
    "                decoder_fn=decoder_fn,\n",
    "                inputs=decoder_inputs_embedded,\n",
    "                sequence_length=decoder_inputs_length,\n",
    "                time_major=True,\n",
    "                scope=scope,\n",
    "            ))\n",
    "\n",
    "    if forward_only:\n",
    "        decoder_logits = decoder_outputs\n",
    "    else:\n",
    "        #\n",
    "        decoder_logits = output_fn(decoder_outputs)\n",
    "\n",
    "    #vocab 사이즈 만큼의 각각 단어의 확률값으로 표현된 리스트의 순서열을 얻고\n",
    "    #argmax 연산을 통해서 최대값을 찾게 됩니다.\n",
    "    decoder_prediction = tf.argmax(decoder_logits, axis=-1, name='decoder_prediction')\n",
    "\n",
    "    #loss 계산을 위한 logit과 targets을 출력\n",
    "    logits = tf.transpose(decoder_logits, [1, 0, 2])\n",
    "    targets = tf.transpose(decoder_targets, [1, 0])\n",
    "\n",
    "    if not forward_only:\n",
    "        #train 모델인 경우 loss 값을 정의\n",
    "        seq_loss = seq2seq.sequence_loss(logits=logits, targets=targets,weights=target_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init_decoder\n",
    "decoder_cell을 가지고 dynamic_rnn Layer를 생성하고 encoder 에서 나온 encoder_state를 연결합니다.  \n",
    "attention의 경우 encoder 단계에서의 각 단계의 state와 output에서 중간 단계의 값을 다시 decoder 구조에 연결합니다.  \n",
    "![](http://i.imgur.com/QRdjS8z.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#params 초기화\n",
    "params = tf.trainable_variables()\n",
    "\n",
    "gradient_norms = []\n",
    "updates_list = []\n",
    "\n",
    "#Optimizer를 통하여 학습을 진행\n",
    "opt = tf.train.AdamOptimizer(learning_rate)\n",
    "#위에서 진행한 모든 네트워크 구조를 지나온 결과값인 loss 에서 gradients 계산하고\n",
    "gradients = tf.gradients(seq_loss, params)\n",
    "\n",
    "#clipped_gradients를 구하고\n",
    "clipped_gradients, norm = tf.clip_by_global_norm(gradients, max_gradient_norm)\n",
    "#계산이나 결과에서 사용되지는 않지만 텐서보드등 에서 표현하기 위해서\n",
    "gradient_norms.append(norm)\n",
    "#opt.apply_gradients 를 통하여 실제 params의 업데이트를 하고\n",
    "updates_list.append(opt.apply_gradients(zip(clipped_gradients, params), global_step=global_step))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder\n",
    "\n",
    "최종모델 그래프에서 optimizer(adam)에 모든 그래프 간선이 연결되는것을 확인 할 수 있습니다.\n",
    "\n",
    "![](http://imgur.com/XKLBATg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(in_session, in_encoder_inputs, in_encoder_inputs_length, in_decoder_inputs, in_decoder_inputs_length, in_target_weights):\n",
    "    #placeholder 로 정의한 데이터 파이프 라인에\n",
    "    #get_batch 등으로 모델 외부에서 주입할 데이터를 정의합니다.\n",
    "    input_feed = {\n",
    "        encoder_inputs: in_encoder_inputs,\n",
    "        encoder_inputs_length: in_encoder_inputs_length,\n",
    "        decoder_inputs: in_decoder_inputs,\n",
    "        decoder_inputs_length: in_decoder_inputs_length,\n",
    "        target_weights: in_target_weights\n",
    "    }\n",
    "    #학습 모델이 아니라면 출력에 필요한 OP 만 묶어서 계산하고\n",
    "    if forward_only:\n",
    "        output_feed = [decoder_logits, decoder_prediction, encoder_state, decoder_state]\n",
    "        logits, prediction, encoder_embedding, decoder_embedding = in_session.run(output_feed, input_feed)\n",
    "        return None, None, logits, prediction, encoder_embedding, decoder_embedding\n",
    "    #학슴 모델이라면 updates 계산을 통해 학습을 진행 합니다.\n",
    "    else:\n",
    "        output_feed = [updates_list, gradient_norms, seq_loss, encoder_state, decoder_state]\n",
    "        updates, gradient, loss, encoder_embedding, decoder_embedding = in_session.run(output_feed, input_feed)\n",
    "        return gradient, loss, None, None, encoder_embedding, decoder_embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model with fresh parameters.\n",
      "[[]]\n",
      "3 24 119 27 974 9 3 3 17 4016 7885 47 420 88 3853 3 953 3 61 42 10 3 4 196 4\n",
      " 70 6 8 152 24 5 79 324 45 3 6 56 16 5 13 123 45 7 4\n",
      "\n",
      "  reading data line 1000\n",
      "  reading data line 2000\n",
      "  reading data line 3000\n",
      "  reading data line 4000\n",
      "  reading data line 5000\n",
      "  reading data line 6000\n",
      "  reading data line 7000\n",
      "  reading data line 8000\n",
      "  reading data line 9000\n",
      "  reading data line 10000\n",
      "  reading data line 11000\n",
      "  reading data line 12000\n",
      "  reading data line 13000\n",
      "  reading data line 14000\n",
      "  reading data line 15000\n",
      "  reading data line 16000\n",
      "  reading data line 17000\n",
      "  reading data line 18000\n",
      "  reading data line 19000\n",
      "  reading data line 20000\n",
      "  reading data line 21000\n",
      "  reading data line 22000\n",
      "  reading data line 23000\n",
      "  reading data line 24000\n",
      "  reading data line 25000\n",
      "  reading data line 26000\n",
      "  reading data line 27000\n",
      "  reading data line 28000\n",
      "  reading data line 29000\n",
      "  reading data line 30000\n",
      "  reading data line 31000\n",
      "  reading data line 32000\n",
      "  reading data line 33000\n",
      "  reading data line 34000\n",
      "  reading data line 35000\n",
      "  reading data line 36000\n",
      "  reading data line 37000\n",
      "  reading data line 38000\n",
      "  reading data line 39000\n",
      "  reading data line 40000\n",
      "  reading data line 41000\n",
      "  reading data line 42000\n",
      "  reading data line 43000\n",
      "  reading data line 44000\n",
      "  reading data line 45000\n",
      "  reading data line 46000\n",
      "  reading data line 47000\n",
      "  reading data line 48000\n",
      "  reading data line 49000\n",
      "  reading data line 50000\n",
      "  reading data line 51000\n",
      "  reading data line 52000\n",
      "  reading data line 53000\n",
      "  reading data line 54000\n",
      "  reading data line 55000\n",
      "  reading data line 56000\n",
      "  reading data line 57000\n",
      "  reading data line 58000\n",
      "  reading data line 59000\n",
      "  reading data line 60000\n",
      "  reading data line 61000\n",
      "  reading data line 62000\n",
      "  reading data line 63000\n",
      "  reading data line 64000\n",
      "  reading data line 65000\n",
      "  reading data line 66000\n",
      "  reading data line 67000\n",
      "  reading data line 68000\n",
      "  reading data line 69000\n",
      "  reading data line 70000\n",
      "  reading data line 71000\n",
      "  reading data line 72000\n",
      "  reading data line 73000\n",
      "  reading data line 74000\n",
      "  reading data line 75000\n",
      "  reading data line 76000\n",
      "  reading data line 77000\n",
      "  reading data line 78000\n",
      "  reading data line 79000\n",
      "  reading data line 80000\n",
      "  reading data line 81000\n",
      "  reading data line 82000\n",
      "  reading data line 83000\n",
      "  reading data line 84000\n",
      "  reading data line 85000\n",
      "  reading data line 86000\n",
      "  reading data line 87000\n",
      "  reading data line 88000\n",
      "  reading data line 89000\n",
      "  reading data line 90000\n",
      "  reading data line 91000\n",
      "  reading data line 92000\n",
      "  reading data line 93000\n",
      "  reading data line 94000\n",
      "  reading data line 95000\n",
      "  reading data line 96000\n",
      "  reading data line 97000\n",
      "  reading data line 98000\n",
      "  reading data line 99000\n",
      "  reading data line 100000\n",
      "  reading data line 101000\n",
      "  reading data line 102000\n",
      "  reading data line 103000\n",
      "  reading data line 104000\n",
      "  reading data line 105000\n",
      "  reading data line 106000\n",
      "  reading data line 107000\n",
      "  reading data line 108000\n",
      "  reading data line 109000\n",
      "  reading data line 110000\n",
      "  reading data line 111000\n",
      "  reading data line 112000\n",
      "  reading data line 113000\n",
      "  reading data line 114000\n",
      "  reading data line 115000\n",
      "  reading data line 116000\n",
      "  reading data line 117000\n",
      "  reading data line 118000\n",
      "  reading data line 119000\n",
      "  reading data line 120000\n",
      "  reading data line 121000\n",
      "  reading data line 122000\n",
      "  reading data line 123000\n",
      "  reading data line 124000\n",
      "  reading data line 125000\n",
      "  reading data line 126000\n",
      "  reading data line 127000\n",
      "  reading data line 128000\n",
      "  reading data line 129000\n",
      "  reading data line 130000\n",
      "  reading data line 131000\n",
      "  reading data line 132000\n",
      "  reading data line 133000\n",
      "  reading data line 134000\n",
      "  reading data line 135000\n",
      "  reading data line 136000\n",
      "  reading data line 137000\n",
      "  reading data line 138000\n",
      "  reading data line 139000\n",
      "  reading data line 140000\n",
      "  reading data line 141000\n",
      "  reading data line 142000\n",
      "  reading data line 143000\n",
      "  reading data line 144000\n",
      "  reading data line 145000\n",
      "  reading data line 146000\n",
      "  reading data line 147000\n",
      "  reading data line 148000\n",
      "  reading data line 149000\n",
      "  reading data line 150000\n",
      "  reading data line 151000\n",
      "  reading data line 152000\n",
      "  reading data line 153000\n",
      "  reading data line 154000\n",
      "  reading data line 155000\n",
      "  reading data line 156000\n",
      "  reading data line 157000\n",
      "  reading data line 158000\n",
      "  reading data line 159000\n",
      "  reading data line 160000\n",
      "  reading data line 161000\n",
      "  reading data line 162000\n",
      "  reading data line 163000\n",
      "  reading data line 164000\n",
      "  reading data line 165000\n",
      "  reading data line 166000\n",
      "  reading data line 167000\n",
      "  reading data line 168000\n",
      "  reading data line 169000\n",
      "  reading data line 170000\n",
      "  reading data line 171000\n",
      "  reading data line 172000\n",
      "  reading data line 173000\n",
      "  reading data line 174000\n",
      "  reading data line 175000\n",
      "  reading data line 176000\n",
      "  reading data line 177000\n",
      "  reading data line 178000\n",
      "  reading data line 179000\n",
      "  reading data line 180000\n",
      "  reading data line 181000\n",
      "  reading data line 182000\n",
      "  reading data line 183000\n",
      "  reading data line 184000\n",
      "  reading data line 185000\n",
      "  reading data line 186000\n",
      "  reading data line 187000\n",
      "  reading data line 188000\n",
      "  reading data line 189000\n",
      "  reading data line 190000\n",
      "  reading data line 191000\n",
      "  reading data line 192000\n",
      "  reading data line 193000\n",
      "  reading data line 194000\n",
      "  reading data line 195000\n",
      "  reading data line 196000\n",
      "  reading data line 197000\n",
      "  reading data line 198000\n",
      "  reading data line 199000\n",
      "  reading data line 200000\n",
      "  reading data line 201000\n",
      "  reading data line 202000\n",
      "  reading data line 203000\n",
      "  reading data line 204000\n",
      "  reading data line 205000\n",
      "  reading data line 206000\n",
      "  reading data line 207000\n",
      "  reading data line 208000\n",
      "  reading data line 209000\n",
      "  reading data line 210000\n",
      "  reading data line 211000\n",
      "  reading data line 212000\n",
      "  reading data line 213000\n",
      "  reading data line 214000\n",
      "  reading data line 215000\n",
      "  reading data line 216000\n",
      "  reading data line 217000\n",
      "  reading data line 218000\n",
      "  reading data line 219000\n",
      "  reading data line 220000\n",
      "  reading data line 221000\n",
      "global step 2 learning rate 0.0010 step-time 0.01 perplexity 1.20 loss 0.18\n",
      "global step 4 learning rate 0.0010 step-time 0.00 perplexity 1.20 loss 0.18\n",
      "global step 6 learning rate 0.0010 step-time 0.00 perplexity 1.20 loss 0.18\n",
      "global step 8 learning rate 0.0010 step-time 0.00 perplexity 1.20 loss 0.18\n",
      "global step 10 learning rate 0.0010 step-time 0.00 perplexity 1.20 loss 0.18\n",
      "global step 12 learning rate 0.0010 step-time 0.00 perplexity 1.19 loss 0.18\n",
      "global step 14 learning rate 0.0010 step-time 0.00 perplexity 1.19 loss 0.17\n",
      "global step 16 learning rate 0.0010 step-time 0.00 perplexity 1.19 loss 0.17\n",
      "global step 18 learning rate 0.0010 step-time 0.00 perplexity 1.16 loss 0.15\n",
      "global step 20 learning rate 0.0010 step-time 0.00 perplexity 1.17 loss 0.15\n",
      "global step 22 learning rate 0.0010 step-time 0.00 perplexity 1.17 loss 0.16\n",
      "global step 24 learning rate 0.0010 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 26 learning rate 0.0010 step-time 0.00 perplexity 1.15 loss 0.14\n",
      "global step 28 learning rate 0.0010 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 30 learning rate 0.0010 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 32 learning rate 0.0010 step-time 0.00 perplexity 1.15 loss 0.14\n",
      "global step 34 learning rate 0.0010 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 36 learning rate 0.0010 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 38 learning rate 0.0010 step-time 0.00 perplexity 1.15 loss 0.14\n",
      "global step 40 learning rate 0.0010 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 42 learning rate 0.0010 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44 learning rate 0.0010 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 46 learning rate 0.0010 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 48 learning rate 0.0010 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 50 learning rate 0.0010 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52 learning rate 0.0010 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 54 learning rate 0.0010 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 56 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 58 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 60 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 62 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 64 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 66 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 68 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 70 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 72 learning rate 0.0009 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 74 learning rate 0.0009 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 76 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 78 learning rate 0.0009 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 80 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 82 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 84 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 86 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 88 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 90 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 92 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 94 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 96 learning rate 0.0009 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 98 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 100 learning rate 0.0009 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 102 learning rate 0.0009 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 104 learning rate 0.0009 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 106 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 108 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 110 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 112 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 114 learning rate 0.0009 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 116 learning rate 0.0009 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 118 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 120 learning rate 0.0009 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 122 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 124 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 126 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 128 learning rate 0.0009 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 130 learning rate 0.0009 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 132 learning rate 0.0008 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 134 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 136 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 138 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 140 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 142 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 144 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 146 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 148 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 150 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 152 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 154 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 156 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 158 learning rate 0.0008 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 160 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 162 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 164 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 166 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 168 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 170 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 172 learning rate 0.0008 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 174 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 176 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 178 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 180 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 182 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 184 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 186 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 188 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 190 learning rate 0.0008 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 192 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 194 learning rate 0.0008 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 196 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 198 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 200 learning rate 0.0008 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 202 learning rate 0.0008 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 204 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 206 learning rate 0.0007 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 208 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 210 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 212 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 214 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 216 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 218 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 220 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 222 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 224 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 226 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 228 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 230 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 232 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 234 learning rate 0.0007 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 236 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 238 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 240 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 242 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 244 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 246 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 248 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 250 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 252 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 254 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 256 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 258 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 260 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 262 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 264 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 266 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 268 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 270 learning rate 0.0007 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 272 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 274 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 276 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 278 learning rate 0.0007 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 280 learning rate 0.0007 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 282 learning rate 0.0007 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 284 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 286 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 288 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 290 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 292 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 294 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 296 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 298 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 300 learning rate 0.0006 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 302 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 304 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 306 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 308 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 310 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 312 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 314 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 316 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 318 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 320 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 322 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 324 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 326 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 328 learning rate 0.0006 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 330 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 332 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 334 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 336 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 338 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 340 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 342 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 344 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 346 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 348 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 350 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 352 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 354 learning rate 0.0006 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 356 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 358 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 360 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 362 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 364 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 366 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 368 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 370 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 372 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 374 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 376 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 378 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 380 learning rate 0.0006 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 382 learning rate 0.0006 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 384 learning rate 0.0006 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 386 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 388 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 390 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 392 learning rate 0.0005 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 394 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 396 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 398 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 400 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 402 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 404 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 406 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 408 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 410 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 412 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 414 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 416 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 418 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 420 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 422 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 424 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 426 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 428 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 430 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 432 learning rate 0.0005 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 434 learning rate 0.0005 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 436 learning rate 0.0005 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 438 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 440 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 442 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 444 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 446 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 448 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 450 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 452 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 454 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 456 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 458 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 460 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 462 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 464 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 466 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 468 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 470 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 472 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 474 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 476 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 478 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 480 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 482 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 484 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 486 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 488 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 490 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 492 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 494 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 496 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 498 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 500 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 502 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 504 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 506 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 508 learning rate 0.0005 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 510 learning rate 0.0005 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 512 learning rate 0.0005 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 514 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 516 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 518 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 520 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 522 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 524 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 526 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 528 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 530 learning rate 0.0004 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 532 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 534 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 536 learning rate 0.0004 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 538 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 540 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 542 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 544 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 546 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 548 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 550 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 552 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 554 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 556 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 558 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 560 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 562 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 564 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 566 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 568 learning rate 0.0004 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 570 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 572 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 574 learning rate 0.0004 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 576 learning rate 0.0004 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 578 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 580 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 582 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 584 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 586 learning rate 0.0004 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 588 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 590 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 592 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 594 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 596 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 598 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 600 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 602 learning rate 0.0004 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 604 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 606 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 608 learning rate 0.0004 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 610 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 612 learning rate 0.0004 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 614 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 616 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 618 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 620 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 622 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 624 learning rate 0.0004 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 626 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 628 learning rate 0.0004 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 630 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 632 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 634 learning rate 0.0004 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 636 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 638 learning rate 0.0004 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 640 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 642 learning rate 0.0004 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 644 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 646 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 648 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 650 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 652 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 654 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 656 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 658 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 660 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 662 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 664 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 666 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 668 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 670 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 672 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 674 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 676 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 678 learning rate 0.0003 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 680 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 682 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 684 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 686 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 688 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 690 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 692 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 694 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 696 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 698 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 700 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 702 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 704 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 706 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 708 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 710 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 712 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 714 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 716 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 718 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 720 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 722 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 724 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 726 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 728 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 730 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 732 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 734 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 736 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 738 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 740 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 742 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 744 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 746 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 748 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 750 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 752 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 754 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 756 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 758 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 760 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 762 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 764 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 766 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 768 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 770 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 772 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 774 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 776 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 778 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 780 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 782 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 784 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 786 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 788 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 790 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 792 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 794 learning rate 0.0003 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 796 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 798 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 800 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 802 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 804 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 806 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 808 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 810 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 812 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 814 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 816 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 818 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 820 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 822 learning rate 0.0003 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 824 learning rate 0.0003 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 826 learning rate 0.0003 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 828 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 830 learning rate 0.0003 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 832 learning rate 0.0003 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 834 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 836 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 838 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 840 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 842 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 844 learning rate 0.0002 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 846 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 848 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 850 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 852 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 854 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 856 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 858 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 860 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 862 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 864 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 866 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 868 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 870 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 872 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 874 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 876 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 878 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 880 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 882 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 884 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 886 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 888 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 890 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 892 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 894 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 896 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 898 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 900 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 902 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 904 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 906 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 908 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 910 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 912 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 914 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 916 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 918 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 920 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 922 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 924 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 926 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 928 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 930 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 932 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 934 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 936 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 938 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 940 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 942 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 944 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 946 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 948 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 950 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 952 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 954 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 956 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 958 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 960 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 962 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 964 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 966 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 968 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 970 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 972 learning rate 0.0002 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 974 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 976 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 978 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 980 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 982 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 984 learning rate 0.0002 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 986 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 988 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 990 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 992 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 994 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 996 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 998 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1000 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1002 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1004 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1006 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1008 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1010 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1012 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1014 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1016 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1018 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1020 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1022 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1024 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1026 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1028 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1030 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1032 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1034 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1036 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1038 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1040 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1042 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1044 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1046 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1048 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1050 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1052 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1054 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1056 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1058 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1060 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1062 learning rate 0.0002 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1064 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1066 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1068 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1070 learning rate 0.0002 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1072 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1074 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1076 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1078 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1080 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1082 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1084 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1086 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1088 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1090 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1092 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1094 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1096 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1098 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1100 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1102 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1104 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1106 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1108 learning rate 0.0002 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1110 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1112 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1114 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1116 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1118 learning rate 0.0002 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1120 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1122 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1124 learning rate 0.0002 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 1126 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1128 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1130 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1132 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1134 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1136 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1138 learning rate 0.0002 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1140 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1142 learning rate 0.0002 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1144 learning rate 0.0002 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1146 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1148 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1150 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1152 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 1154 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1156 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1158 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1160 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1162 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1164 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1166 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 1168 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1170 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1172 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1174 learning rate 0.0001 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 1176 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1178 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1180 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1182 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1184 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 1186 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1188 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1190 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1192 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1194 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1196 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1198 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1200 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1202 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1204 learning rate 0.0001 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1206 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1208 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1210 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1212 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1214 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1216 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1218 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1220 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1222 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1224 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1226 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1228 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1230 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1232 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1234 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1236 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1238 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1240 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1242 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1244 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1246 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1248 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1250 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1252 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1254 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1256 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1258 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1260 learning rate 0.0001 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1262 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1264 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1266 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1268 learning rate 0.0001 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 1270 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1272 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1274 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1276 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1278 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1280 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1282 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1284 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1286 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1288 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1290 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1292 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1294 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1296 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1298 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1300 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1302 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1304 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1306 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1308 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1310 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1312 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1314 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1316 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1318 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1320 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1322 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1324 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1326 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1328 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1330 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1332 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1334 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1336 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1338 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1340 learning rate 0.0001 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1342 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1344 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1346 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1348 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1350 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1352 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1354 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1356 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1358 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1360 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1362 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1364 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1366 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1368 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1370 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1372 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1374 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1376 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1378 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1380 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1382 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1384 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1386 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1388 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1390 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1392 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1394 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1396 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1398 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1400 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1402 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1404 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1406 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1408 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1410 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1412 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1414 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 1416 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1418 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1420 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1422 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1424 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1426 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1428 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1430 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1432 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1434 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1436 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1438 learning rate 0.0001 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1440 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 1442 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1444 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1446 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1448 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1450 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1452 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1454 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1456 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1458 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1460 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1462 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1464 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1466 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1468 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1470 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1472 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1474 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1476 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1478 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1480 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1482 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1484 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1486 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1488 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1490 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1492 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1494 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1496 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1498 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1500 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 1502 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1504 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1506 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1508 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1510 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1512 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1514 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1516 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1518 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1520 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1522 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1524 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1526 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1528 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1530 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1532 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1534 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1536 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1538 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1540 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1542 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1544 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1546 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1548 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1550 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1552 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1554 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1556 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1558 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1560 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1562 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1564 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1566 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1568 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1570 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1572 learning rate 0.0001 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1574 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1576 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1578 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1580 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1582 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1584 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1586 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1588 learning rate 0.0001 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 1590 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1592 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1594 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1596 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1598 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1600 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1602 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1604 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1606 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1608 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1610 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1612 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1614 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1616 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1618 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1620 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1622 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1624 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1626 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1628 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1630 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1632 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1634 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1636 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1638 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1640 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1642 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1644 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1646 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1648 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1650 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1652 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1654 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1656 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1658 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1660 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1662 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1664 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1666 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1668 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1670 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1672 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1674 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1676 learning rate 0.0001 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 1678 learning rate 0.0001 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 1680 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1682 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1684 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1686 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1688 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1690 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1692 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1694 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1696 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1698 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1700 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1702 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1704 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1706 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1708 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1710 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1712 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1714 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1716 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1718 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1720 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1722 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1724 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1726 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1728 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1730 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1732 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1734 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1736 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1738 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1740 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1742 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1744 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1746 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1748 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1750 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1752 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1754 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1756 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1758 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1760 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1762 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1764 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1766 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1768 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1770 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1772 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1774 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1776 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1778 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1780 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1782 learning rate 0.0001 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1784 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1786 learning rate 0.0001 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1788 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1790 learning rate 0.0001 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1792 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1794 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1796 learning rate 0.0001 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1800 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1826 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1834 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1838 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 1840 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1846 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 1848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1882 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1890 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1892 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1904 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 1906 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1908 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1912 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 1914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1926 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1964 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 1966 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1970 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 1972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 1980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 1982 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 1984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1988 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 1992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 1994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 1996 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 1998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2000 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2004 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2030 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2036 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 2038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2052 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2056 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2088 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2100 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 2102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2108 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2116 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2126 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2132 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2134 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2142 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2170 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 2172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2192 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2200 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2218 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2224 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 2226 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 2228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2232 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2246 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2266 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2268 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2292 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 2294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2298 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 2300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2302 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2320 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2334 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2344 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2350 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2352 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2392 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2402 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2404 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2408 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 2410 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2422 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 2424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2438 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 2440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2442 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2444 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2450 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2470 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2550 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2570 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2600 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2604 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2636 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 2638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2650 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2674 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2680 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 2682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2692 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2706 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2722 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2736 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2760 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2772 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2784 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2812 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2820 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2840 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 2842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2850 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2866 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2878 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2882 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2902 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2906 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2908 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2928 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 2930 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2940 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 2942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2962 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 2964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 2966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2970 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 2972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2974 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 2976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 2992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 2996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 2998 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3000 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3018 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3024 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 3026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3030 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3040 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3042 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3052 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3054 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3060 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3072 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 3074 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3090 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3116 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 3118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3120 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3126 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 3128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3132 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3134 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3136 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3152 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3158 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 3160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3162 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 3164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3166 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3168 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 3170 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3176 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3178 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3186 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 3198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3202 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3210 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3212 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3214 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3216 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 3218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3232 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3244 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3250 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3256 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3274 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3290 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 3292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3296 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 3298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3310 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3316 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3334 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3336 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3346 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3350 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 3352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3358 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 3360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3368 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3394 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3396 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 3398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 3406 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 3408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3412 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3424 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3446 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3454 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3460 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3462 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3466 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3494 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3498 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 3500 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 3502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3506 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3508 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 3510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3522 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3528 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3538 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3544 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3574 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 3576 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3578 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 3580 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3594 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3596 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 3614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3630 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 3632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3642 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3652 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3658 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 3660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3666 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3668 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3670 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3682 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3698 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3708 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3730 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3738 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3744 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3760 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3762 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3780 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3802 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3816 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 3822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3830 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3834 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3844 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3852 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 3854 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 3856 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3876 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3884 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 3886 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3888 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3896 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3898 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3920 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 3922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3934 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3948 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3958 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 3962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3964 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 3966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3986 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 3988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 3992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 3994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 3996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 3998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4002 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4016 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4018 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4022 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 4030 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 4032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4044 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 4048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4052 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4058 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4070 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4094 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4106 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4110 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4138 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 4140 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4142 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4162 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 4164 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4178 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 4180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4198 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4212 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4226 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4230 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4234 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 4238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4252 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4254 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4260 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4268 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4288 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4292 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4296 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4308 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4312 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4316 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4330 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4338 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 4340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4366 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4368 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4376 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4400 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4402 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 4404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4412 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4420 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4440 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4442 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4444 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 4446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4452 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4454 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4458 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4470 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4486 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4488 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4494 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4502 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4508 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4512 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 4514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4544 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 4546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4554 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4556 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 4558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4564 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4566 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4580 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4588 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4598 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4604 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4638 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4642 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4644 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 4654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4662 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4714 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4722 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4730 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4736 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4744 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4750 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4756 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4766 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4776 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4790 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4792 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4796 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4798 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4800 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4806 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4812 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4816 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4820 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4822 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 4824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4828 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4830 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4834 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4842 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4852 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4856 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 4862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4868 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4886 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4888 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4896 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4914 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4940 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4958 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4960 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 4962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4966 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 4968 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4972 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 4974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4980 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 4982 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 4984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 4986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 4988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4990 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 4992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 4994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 4996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 4998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5012 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5034 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5064 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5068 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 5070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5072 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5088 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 5090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5110 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5114 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5134 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5150 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5158 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5184 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5212 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5244 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 5278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5280 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5282 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5290 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5300 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5304 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5322 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 5324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5330 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5342 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5350 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5368 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5374 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 5376 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5380 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5398 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5414 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5438 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5450 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5452 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5470 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5478 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 5480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 5486 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5490 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5492 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5504 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5508 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5516 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5522 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5552 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5584 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5588 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5598 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 5600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5626 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5630 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5640 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5642 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5656 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5660 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 5662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5672 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5682 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5692 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 5694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5698 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5706 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5714 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5716 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5718 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5722 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5730 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5732 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5734 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5740 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5762 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5764 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5768 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5774 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5776 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5780 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5782 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5796 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5802 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5808 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5852 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5860 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5862 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5870 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5878 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5886 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5888 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5892 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 5902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5930 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5932 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 5936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5938 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 5942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5944 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5946 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5956 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5960 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5964 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 5966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5972 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 5974 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 5976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 5982 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5990 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 5992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5994 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 5996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 5998 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6002 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6006 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 6008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6048 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6056 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6064 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6094 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 6096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6102 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 6110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6116 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6120 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6126 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6140 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6142 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6156 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 6158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6184 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6194 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 6196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6210 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 6212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6222 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6258 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6268 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 6270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6284 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 6286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6300 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6306 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6314 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 6316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 6318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6324 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6346 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6348 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6374 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6386 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 6388 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6412 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6418 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6422 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6424 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6428 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6436 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6452 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6458 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 6460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6482 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6510 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6518 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6520 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 6522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 6526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6554 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 6566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6568 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6572 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6590 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6596 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6604 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6620 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6638 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6640 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6642 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 6644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6652 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 6654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6656 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6668 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6672 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6684 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 6686 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6696 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6698 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 6700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6716 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 6734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6740 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6758 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6776 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 6778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6780 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6790 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6798 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6804 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6808 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6822 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6846 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6860 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6900 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6906 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 6908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6938 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6940 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 6942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6944 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 6946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6950 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 6952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 6974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 6978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6986 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 6990 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 6992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 6996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 6998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7006 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 7008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7018 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7028 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7034 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7068 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7074 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7106 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7140 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 7142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 7150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7152 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7158 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7174 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7180 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 7182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7196 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7204 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7210 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 7212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7216 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7222 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7234 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7238 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7242 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7244 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7246 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7264 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7266 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7278 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7286 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7290 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7298 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7302 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7306 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7326 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 7328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7336 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 7338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7346 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 7358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7364 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7366 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7376 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 7378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7382 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7386 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7388 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 7390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7408 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7414 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7430 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7440 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7442 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7470 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7478 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7484 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7498 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7506 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 7508 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7524 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7528 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7532 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7540 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7550 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7552 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 7566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7572 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 7574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7580 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7582 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7598 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7602 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7608 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7614 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7618 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7620 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7648 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7652 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7654 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7660 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7668 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7672 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7702 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7714 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7718 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7726 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7730 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7732 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7738 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7748 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7756 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 7772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7786 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 7788 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7800 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7806 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 7808 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7814 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7828 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7844 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7848 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7852 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7858 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7860 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 7862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7870 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7876 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7880 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 7882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7884 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7892 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 7894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7930 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7936 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 7938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 7962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 7980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 7982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 7986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 7988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 7994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 7998 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8026 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8034 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 8036 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8038 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8040 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8050 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8086 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8090 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8096 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8110 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8140 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8152 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8158 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8164 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8166 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8178 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 8188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8196 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8200 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8210 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8212 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 8214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8228 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8234 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8238 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8260 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8262 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8266 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8276 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8280 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8290 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8292 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8298 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8302 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8304 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8308 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 8310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8312 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8328 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8336 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8338 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8358 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8364 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8376 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8392 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8394 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 8396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8402 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8404 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8408 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8418 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8420 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8438 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8440 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8442 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8444 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8446 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8456 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8466 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8508 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8528 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8538 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8546 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8550 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8552 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8554 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8556 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8574 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8600 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 8602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 8604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8606 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8608 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8616 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8640 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8644 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8654 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 8656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8658 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8666 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8678 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8690 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8706 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8712 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8722 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8732 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8734 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8736 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8740 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8744 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8774 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8794 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8806 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8808 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 8812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8824 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8834 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8872 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8900 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8902 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8906 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8908 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8912 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8914 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8934 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8938 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8944 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8948 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 8950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8958 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8962 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 8964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8970 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 8972 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 8982 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 8984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8986 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8988 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 8990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 8992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 8994 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 8996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 8998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9014 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 9020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9034 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9052 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9060 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9074 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9080 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9088 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9096 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9120 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 9122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9146 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9154 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9158 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9160 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9162 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9176 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9178 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9202 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 9204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9206 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9222 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 9228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9230 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9232 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 9234 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9236 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 9238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9248 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9250 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9254 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 9256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9266 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9268 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9278 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9292 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9296 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 9298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9306 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9322 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9330 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9332 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 9334 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 9336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9344 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9354 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9404 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9410 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9412 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9416 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 9436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9440 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9456 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9474 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9480 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9482 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9506 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 9526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9528 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9532 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9542 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9544 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9550 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9554 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9566 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9580 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9582 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9594 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 9596 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 9598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9602 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 9604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9608 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9624 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9628 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9630 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9632 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9636 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9640 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9642 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 9644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9678 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9684 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 9686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9696 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9700 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9704 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9706 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9712 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9762 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9774 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9790 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9792 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9794 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9798 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 9814 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9816 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9828 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 9830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9838 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 9852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9856 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9878 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9898 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9904 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9910 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9924 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 9926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 9960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9968 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 9970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9972 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9974 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 9980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9986 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 9988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 9992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 9996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 9998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10008 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10018 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10022 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10024 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10028 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10036 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10048 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10050 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 10052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10064 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10070 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10072 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10076 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10078 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10092 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10132 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10140 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10152 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10170 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10178 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10204 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10216 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 10218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10220 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10228 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10242 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10244 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10250 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10252 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10254 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10256 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10298 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10306 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10334 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10338 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10342 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 10344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10350 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10370 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10386 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10392 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10394 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 10396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10442 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10456 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 10458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10466 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10472 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10474 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 10476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10488 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10492 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 10498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10516 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10520 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 10522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10524 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10552 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 10554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10568 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10572 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10594 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10600 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10612 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10618 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10624 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10632 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10636 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10642 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 10644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10646 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10648 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10656 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 10658 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 10660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10662 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10676 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10690 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10692 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 10694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10708 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10710 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10714 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10776 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10778 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10780 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10812 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 10814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10820 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10828 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10854 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10856 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10870 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10874 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10892 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10916 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10924 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10934 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10940 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10964 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 10966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10968 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 10978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 10980 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10984 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 10986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 10988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10990 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 10992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 10996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 10998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11028 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11030 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11032 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11034 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11036 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11038 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11044 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11070 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11072 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11076 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11080 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 11090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11096 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11114 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11126 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11134 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11140 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11146 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11152 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11158 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11166 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11168 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11172 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 11174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11176 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11178 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 11180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11188 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11204 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 11206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11210 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11220 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11226 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11252 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11258 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 11260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11272 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11274 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11276 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11290 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 11296 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11318 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11322 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11328 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11332 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11334 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11336 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11340 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11346 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11352 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11370 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11374 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11376 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11382 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11396 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11398 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11412 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11416 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11418 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11428 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11434 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11436 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 11438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11440 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11442 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11458 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11470 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11474 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 11502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11516 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11522 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11550 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11584 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11598 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11604 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11616 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11624 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11630 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11634 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 11636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11660 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11672 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11680 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11684 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11698 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 11708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11724 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 11726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11736 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11738 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11744 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11748 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11754 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 11756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11764 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11772 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11774 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 11776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11780 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11782 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11790 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11794 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11840 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11844 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11852 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11854 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11876 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11888 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 11914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11916 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 11918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11928 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11940 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11956 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11958 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11962 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11964 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 11966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 11976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 11984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11986 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 11990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 11992 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 11994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 11996 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 11998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12038 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12044 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12064 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12072 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12096 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12098 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 12106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12118 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 12120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12142 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12154 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 12156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12172 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12192 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12210 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12212 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12214 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 12216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12234 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12262 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12286 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12290 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12292 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12296 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12300 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12304 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12322 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 12326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12328 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12370 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 12372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 12382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12390 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12402 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 12404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12430 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12440 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12442 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12456 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12472 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12488 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12508 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 12510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12514 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 12532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12540 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12560 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12572 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12574 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12580 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12602 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12616 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12618 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 12620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12634 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12638 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 12640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12650 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12664 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12692 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12694 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 12696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12710 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12712 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 12714 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12732 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 12734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 12738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12760 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12762 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12764 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12766 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12768 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12772 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12778 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12790 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 12792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12798 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12814 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12838 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 12840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12842 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12844 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12862 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12896 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 12898 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12922 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12924 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 12926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12940 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 12944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12948 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 12950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12970 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 12978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 12984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12986 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 12990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 12992 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 12994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 12996 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 12998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13000 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 13002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13004 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13014 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 13016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13022 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13024 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13034 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13054 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13060 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13066 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 13068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13078 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13080 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13086 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 13088 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13102 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13120 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 13122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13124 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13130 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 13132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13134 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 13150 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 13152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13182 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13194 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13250 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13274 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13288 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13290 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 13292 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 13294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13306 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13314 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13338 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13352 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 13356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13358 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13384 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13410 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 13412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13432 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13438 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13452 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13466 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13470 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13492 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13502 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13504 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13510 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 13512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13516 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13524 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13528 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13544 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13556 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 13562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13570 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13574 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13576 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13578 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13580 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13594 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13596 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13602 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13622 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 13624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13626 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13628 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13630 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13648 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13656 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 13658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13662 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13664 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 13666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13668 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13694 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13704 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13722 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13732 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13736 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13742 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 13744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13762 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 13768 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13788 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 13790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13794 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13798 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13810 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13812 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 13814 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13818 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 13820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13830 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13856 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13866 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13878 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13882 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13906 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13912 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13926 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13934 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13936 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 13938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 13946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13956 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 13958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 13974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 13976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13982 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 13984 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 13986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 13992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 13996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 13998 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14010 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14020 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14030 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14034 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14044 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14054 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 14056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14062 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14064 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 14066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14070 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14080 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14094 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14100 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14104 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14108 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14128 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14132 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14134 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14148 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14166 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 14180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14182 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14212 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14214 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14220 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14224 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14226 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14252 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14254 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14258 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14272 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 14274 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14276 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14302 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14306 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14324 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14354 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14374 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14376 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14384 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 14386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14394 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14402 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14412 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14438 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14440 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 14442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14448 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14454 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14466 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14482 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14490 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14492 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14514 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14528 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14538 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14544 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14570 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 14592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14594 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 14596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14598 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14622 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14630 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14640 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 14642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14644 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14646 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 14648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14650 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14666 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14672 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14688 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 14690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14706 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14736 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14744 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14758 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14778 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 14780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14786 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14788 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 14798 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14802 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14806 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14812 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14818 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 14820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14826 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14832 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14834 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14858 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14866 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14868 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14882 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 14892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14930 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 14932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14936 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14940 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14948 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 14950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 14954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14956 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14960 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 14970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14972 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 14982 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14986 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14988 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 14990 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 14992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 14998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 15004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15020 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15024 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15036 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15040 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15054 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15070 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15074 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15096 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15116 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15128 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15142 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15150 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15180 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15192 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15198 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15206 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 15210 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15222 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15224 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15226 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15250 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15254 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 15256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15258 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15276 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15278 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15288 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15298 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15304 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15306 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15310 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15316 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15346 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 15348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15352 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15388 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 15390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 15416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15418 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15438 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15442 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15446 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15458 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 15460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15464 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15470 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15488 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15490 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15492 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15520 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 15526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15532 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15536 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15538 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 15556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15558 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 15560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15572 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15584 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15586 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15590 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15592 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 15594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15610 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 15612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15616 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15620 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 15622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15626 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15632 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15640 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15660 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15664 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 15666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15674 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15680 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15690 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15708 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15722 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15734 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15736 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15742 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15748 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 15750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15758 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 15772 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15788 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15808 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 15810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15816 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 15818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15820 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 15828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15842 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15852 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 15854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15862 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15876 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 15878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15884 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15890 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15896 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 15898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15912 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15930 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15940 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15950 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15962 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15972 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 15974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 15976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 15982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 15986 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 15988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 15996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 15998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16018 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16020 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16032 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 16034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16050 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16064 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16072 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 16074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16078 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16080 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16088 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 16090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16094 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16096 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16098 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16118 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 16120 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16124 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16132 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16134 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16170 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16202 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 16204 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16226 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 16228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16230 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16238 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 16240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16250 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16252 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16262 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16274 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16276 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16278 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16280 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16282 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16290 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16296 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16298 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 16300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16304 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16322 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16324 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16334 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16340 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16358 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16362 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 16364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16368 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16372 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16380 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16398 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16418 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16422 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16436 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 16438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16440 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16442 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 16446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16452 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16454 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16482 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16490 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 16492 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16512 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16522 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16532 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16548 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16550 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16586 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16606 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16616 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16632 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16642 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16644 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16646 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 16652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16664 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16684 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16722 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16732 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16736 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16750 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16762 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16788 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16804 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16806 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16808 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16810 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16816 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16828 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16840 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16842 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16846 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16852 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16854 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 16858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16862 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16866 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16870 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 16872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16882 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16904 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16912 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16920 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16926 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 16928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 16950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16966 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 16974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16980 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16982 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 16984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 16986 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 16988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 16990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 16996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 16998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17000 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17010 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17028 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17044 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17054 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 17064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17070 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17074 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17076 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17088 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17090 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17100 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17102 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17112 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17116 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17124 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17144 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17150 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17156 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17162 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17176 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17178 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17192 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17198 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17202 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17210 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17216 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17228 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17244 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17262 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 17270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17286 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17294 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17300 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17302 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17304 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17318 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17322 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17330 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17332 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17336 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17352 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17376 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17378 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17408 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17416 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17444 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17448 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 17450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17454 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17460 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 17462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 17476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17480 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17502 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17504 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17510 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17522 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17524 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17534 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17548 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17568 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17572 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17580 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17584 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17600 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17606 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 17608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17626 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17630 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17634 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 17636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17646 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17648 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17670 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 17672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 17682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17684 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17686 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17696 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17714 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 17716 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17722 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17726 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17744 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17756 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17758 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17762 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17768 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17770 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17772 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17780 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17788 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17796 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17834 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17844 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 17846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17854 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17864 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17874 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 17888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17898 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 17900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17910 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17942 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17956 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17960 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17972 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 17976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 17984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 17986 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 17988 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 17990 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 17992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 17994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 17996 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 17998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18004 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18024 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18066 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18072 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18074 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 18094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18102 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18108 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18130 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 18132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18140 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18164 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18166 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18192 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 18194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18204 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18214 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18216 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 18218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18240 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18244 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18248 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18264 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18274 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18282 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 18300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18318 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18328 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18342 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18362 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 18364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18368 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18410 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18412 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18414 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18440 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18452 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18454 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18472 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18490 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18492 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18504 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 18506 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18510 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 18512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18522 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18524 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18528 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18532 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18534 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18538 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18542 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18552 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18554 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18560 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18582 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18588 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18590 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 18592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18594 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18606 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 18608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18636 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18642 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18652 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 18654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18668 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18684 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 18686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18694 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18696 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18704 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18708 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18710 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 18712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18718 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18722 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18724 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18736 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18748 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18760 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18772 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18790 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 18796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18800 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18816 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18818 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18832 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 18834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18842 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18852 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18858 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 18860 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18866 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18880 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18882 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18892 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18910 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 18914 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 18916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 18918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18920 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18926 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 18932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18952 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18956 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18966 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18970 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 18982 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 18988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 18990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18992 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 18994 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 18996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 18998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19018 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 19020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19026 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19034 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 19036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19038 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 19040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 19048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19076 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19094 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 19096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19102 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 19104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 19124 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19142 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19158 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 19160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19178 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19192 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19198 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19214 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19234 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19256 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19258 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19262 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19266 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19276 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 19278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19296 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19304 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19308 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19324 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 19326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 19330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19338 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 19340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19346 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 19358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19360 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19368 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 19376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19378 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19412 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19418 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19420 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19422 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 19424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19454 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19488 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19492 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19502 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19512 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19516 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 19518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19520 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19528 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 19536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19544 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 19546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19560 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19566 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 19568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19570 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19578 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19580 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19582 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19590 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19598 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 19600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19612 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19624 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19650 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19662 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19672 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19676 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19692 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19708 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19716 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19728 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 19742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19750 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19758 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19768 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19774 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19776 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 19778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19788 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19796 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 19798 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19800 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19836 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19874 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19878 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19888 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19892 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19898 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19924 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 19926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 19942 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 19948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19956 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19972 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 19980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 19986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 19992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 19994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 19996 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 19998 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20018 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20030 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20034 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20038 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20050 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20062 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20064 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20070 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20072 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 20074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20076 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20082 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20100 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20110 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20116 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20120 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20136 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20142 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20152 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 20154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20170 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20172 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20192 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20208 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20242 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20246 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20264 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 20266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20282 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20290 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20310 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20328 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 20330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20332 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20338 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20352 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 20360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20376 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20382 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20414 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20418 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20440 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20442 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20454 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20458 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 20460 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20474 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20482 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20502 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20506 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20508 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 20510 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20512 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20522 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 20524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20532 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20548 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20556 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20560 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 20566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20576 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20586 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20602 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20628 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20634 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20648 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20650 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 20652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20684 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20700 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20708 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20716 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20722 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 20724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20738 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20768 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 20772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20780 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20790 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20796 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20802 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20806 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 20808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20812 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20818 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20820 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20822 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 20824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20846 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 20848 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20860 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20868 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 20874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20888 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 20890 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20898 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20900 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 20902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20924 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20948 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20958 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20964 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20968 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20974 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20976 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 20978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 20980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 20984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20988 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 20990 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 20992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 20994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 20996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 20998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21002 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21018 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21024 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21028 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21030 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21036 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21042 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21052 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21076 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21100 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21106 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21150 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21152 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 21184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21198 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21200 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21202 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 21204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21210 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21212 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21226 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21252 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21254 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21256 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21258 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21264 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21266 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21270 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21278 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21286 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21298 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21302 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21312 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21318 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21322 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21324 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21332 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21334 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21338 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21342 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21358 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21384 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21388 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 21390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21392 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21394 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21406 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21408 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21420 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21426 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21432 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 21434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21436 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21438 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21450 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21460 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21468 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21474 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21504 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21508 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21512 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21522 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21524 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21528 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21536 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21548 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 21550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21574 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21580 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21582 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 21596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21602 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21610 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21618 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21622 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21628 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21632 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21646 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21658 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21678 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 21680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21686 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21724 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21740 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21742 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 21744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21758 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21772 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 21802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21810 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21820 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 21826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21828 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21838 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21852 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21854 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 21856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21858 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 21860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21890 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21892 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21932 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21938 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21942 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21950 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 21952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 21954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21956 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21972 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 21980 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 21982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21986 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 21988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21990 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 21992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 21994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 21996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 21998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22000 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 22008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22010 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22030 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22052 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22070 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22072 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22078 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 22080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22084 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22090 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22094 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22096 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22102 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22104 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22124 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22134 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22140 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22158 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22160 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22178 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22204 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 22214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22230 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22254 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22264 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22266 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22268 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22274 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22290 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22296 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22298 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22302 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22324 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22336 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22354 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22362 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22376 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22408 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22410 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 22420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22442 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22452 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22478 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22504 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22512 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22514 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 22532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22554 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22560 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 22562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22564 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22578 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22580 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22584 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22588 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22606 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22612 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22616 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22620 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22622 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 22626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22628 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22634 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22642 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22650 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22654 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22664 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22668 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22672 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22692 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22706 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22712 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.06\n",
      "global step 22714 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22718 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22730 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22732 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22744 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22760 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22762 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 22764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22772 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22776 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 22778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22780 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22782 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22800 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22810 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22820 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 22832 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 22834 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22848 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22912 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 22918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22930 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22942 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 22944 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22946 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22954 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22958 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22970 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22972 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22978 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 22980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 22982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22988 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 22990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 22992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 22996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 22998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23020 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 23022 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23030 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23034 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23036 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 23038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23048 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23056 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23086 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23090 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23108 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23110 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23138 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 23140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23142 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23148 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23152 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23160 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 23162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23172 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23176 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23188 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23196 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23204 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23210 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23222 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 23224 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 23226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23238 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23240 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 23244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23270 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 23272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23276 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23290 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23296 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23320 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 23322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23328 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23356 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23390 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23394 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23406 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23422 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 23450 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23452 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23460 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23468 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23478 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23484 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 23486 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23488 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23504 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23528 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23532 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23552 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23562 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23566 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23568 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23578 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23582 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23586 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23604 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23616 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23624 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23632 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 23634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23640 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23644 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 23656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23662 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23670 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23678 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23680 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23682 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23686 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23694 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23696 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23698 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23702 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23710 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23722 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23732 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23736 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23752 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 23754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23760 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23774 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23808 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23824 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23834 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23840 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23850 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 23852 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 23854 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23856 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23858 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 23862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23870 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23874 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23876 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23878 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23882 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23890 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 23892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23898 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23906 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 23908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23914 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23930 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23938 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 23940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23944 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23946 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23960 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23976 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 23982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 23984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23988 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 23990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 23994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 23996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 23998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24010 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24014 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24022 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24026 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24042 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24060 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 24068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24072 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24110 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24126 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24128 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24152 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24158 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24166 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24182 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24192 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24210 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24212 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24214 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24218 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24238 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 24240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24264 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24270 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 24274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24302 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24322 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24324 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24326 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24328 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24358 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 24360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24362 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 24364 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24372 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24388 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24394 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24404 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24414 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24416 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24424 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24432 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24444 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24456 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24466 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 24480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24482 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24492 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24494 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24500 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24506 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24524 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24570 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24576 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24580 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24582 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24606 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24636 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 24638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24642 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24650 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24656 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24660 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24664 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24670 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24674 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 24686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24710 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24712 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24724 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24726 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24756 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24758 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24768 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24772 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 24774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24782 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24802 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 24804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24808 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24820 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24824 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 24826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24842 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24862 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24874 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24880 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24884 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 24892 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24900 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24904 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24918 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24922 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 24932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24936 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 24938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24952 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24962 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 24964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 24970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24974 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 24986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24988 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 24990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 24992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 24996 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 24998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25010 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25018 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25036 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25060 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25062 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 25064 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25076 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25088 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 25098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25106 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 25108 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25118 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25126 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25166 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25170 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25176 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25188 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 25190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25226 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25242 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25244 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 25246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25256 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25258 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 25260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25264 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 25266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25272 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 25274 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25284 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 25304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25306 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25346 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25354 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25358 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 25360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25382 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25398 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 25400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25404 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 25406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25416 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25418 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25420 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25428 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 25430 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25458 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25460 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25466 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 25468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25484 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 25486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25490 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 25492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25496 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 25498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25502 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25504 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25508 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 25510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25516 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25544 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25568 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25582 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25584 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 25586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25614 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25638 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25660 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25670 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25692 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 25694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25706 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 25716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25728 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25730 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25758 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25776 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25788 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25792 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25806 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25814 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25816 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25820 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 25822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25828 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25840 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25874 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25878 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25888 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25894 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 25896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 25922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25934 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25938 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 25940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25952 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 25954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 25982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 25986 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 25988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 25990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 25994 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 25996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 25998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26004 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 26006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26024 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26026 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26032 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 26034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26042 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26068 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26088 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26096 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26102 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 26104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26116 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 26128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26140 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26158 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26166 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 26168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26176 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26204 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26222 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26224 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 26226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26242 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26244 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26252 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26258 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26268 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26270 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26280 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 26282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26292 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26302 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26304 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26310 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26316 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26320 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 26322 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 26324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26326 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26328 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26332 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 26334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26336 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26338 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26352 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26376 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26398 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26408 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26416 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26418 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26434 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 26436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26466 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 26468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26484 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26490 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 26492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26514 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26516 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26528 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 26540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26572 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 26574 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26576 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26578 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26586 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26594 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26602 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26612 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 26614 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26616 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26630 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26650 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26690 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26698 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26718 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26724 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26726 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 26728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26740 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26744 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 26746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 26756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26764 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26774 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26798 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26814 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26828 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26832 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 26834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26854 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26862 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26870 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 26872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26878 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 26880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26882 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26900 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26904 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26910 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 26922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26926 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26934 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 26936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26938 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26946 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 26948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 26952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26956 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26970 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 26974 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26988 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 26990 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 26992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 26994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 26996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 26998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27000 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27032 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27038 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27044 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27052 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27082 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27088 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27098 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27100 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27104 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27110 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27140 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27152 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 27158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27174 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27192 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27194 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27196 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27208 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27240 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27256 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27264 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27266 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27270 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27274 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27276 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27284 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27296 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27304 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27306 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27316 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 27364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27374 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27384 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27390 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27398 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27434 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27438 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27444 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27450 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27454 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27456 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27458 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27466 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 27468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27470 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27482 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27486 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27492 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27498 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27532 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27536 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27540 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27544 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 27546 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27548 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 27550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27552 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27564 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 27570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27576 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27580 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27596 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27618 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27626 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27628 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27634 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27642 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27656 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27658 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 27660 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 27662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27664 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27668 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 27670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27674 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 27676 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27680 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27684 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27686 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27692 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27694 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27714 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27718 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 27720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27738 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27756 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27762 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27772 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 27776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27780 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27786 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 27788 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27794 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27798 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27816 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27824 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 27826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27858 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27866 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27878 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 27880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27890 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27904 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27906 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 27908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27932 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27942 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27944 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 27946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27956 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27960 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27966 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27970 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27972 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 27980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 27982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 27984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 27986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 27988 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 27990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 27996 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 27998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28004 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28020 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28030 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28042 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28044 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28054 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28062 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 28064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28074 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28082 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28106 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28114 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28120 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28124 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28128 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 28130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28132 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28144 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 28146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28172 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28178 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 28188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28200 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28208 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28254 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28266 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28288 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28290 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 28292 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28298 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28310 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28322 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28328 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28342 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28364 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 28394 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28402 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 28404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28406 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28446 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28464 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28470 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28494 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 28498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28500 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28512 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28518 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 28520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28544 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28552 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28570 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28578 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28594 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28596 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28598 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 28600 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28622 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28630 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28632 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28672 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28674 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 28676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28692 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 28694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28696 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28706 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28732 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 28734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28738 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28744 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28756 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28774 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28776 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28788 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28792 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28802 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 28806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28814 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28840 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 28842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28854 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28864 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 28866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28872 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28900 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28904 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28906 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28928 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 28940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28942 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28954 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28962 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28966 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 28970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28972 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 28974 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 28978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28988 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 28992 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 28994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 28996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 28998 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29006 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 29008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 29012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29016 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29036 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29038 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29050 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29054 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29056 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29060 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29068 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29096 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29098 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 29100 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29106 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29116 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29152 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29154 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29158 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29160 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29166 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29170 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29188 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29190 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29204 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 29218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29230 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29236 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29248 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29260 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29270 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29290 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29296 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29298 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29302 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29306 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29322 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29324 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 29326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29336 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29338 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29340 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29344 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 29346 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29362 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29364 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29366 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29368 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29376 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29408 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29410 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29414 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29416 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29418 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 29424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29428 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29442 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29460 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29466 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29474 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29482 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29486 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29500 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29508 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29516 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29546 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29554 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29556 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29558 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29568 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29572 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 29574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29584 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29596 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29604 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29606 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29618 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29624 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 29626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 29630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29642 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 29644 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29648 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29656 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 29658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29684 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29692 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29696 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29708 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29710 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29716 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29750 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29762 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29774 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29798 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29800 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29808 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29816 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29826 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 29836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29842 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 29844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29850 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29852 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29854 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29856 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29858 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29910 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29916 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29922 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29926 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 29930 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29938 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 29940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29966 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 29968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 29972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 29992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 29994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 29996 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 29998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30016 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30020 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 30042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30060 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30068 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30092 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30102 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30106 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30108 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30128 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30134 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30146 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 30148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30152 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 30154 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 30156 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30158 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30162 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30170 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30202 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30234 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 30248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30252 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 30254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30258 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30262 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30266 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30286 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30320 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30336 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 30338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30354 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30362 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30382 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30392 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30400 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 30402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30404 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30416 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30418 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30440 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30442 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 30454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30482 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30488 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30490 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30494 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30518 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30526 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30534 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30552 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 30554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30566 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30568 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30582 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30588 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30596 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30624 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30626 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30644 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30650 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 30660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30690 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30698 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30704 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30734 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30746 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30760 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30762 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30764 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 30766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30768 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30772 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 30774 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30776 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30790 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30794 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 30796 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30802 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30830 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30852 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30858 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30862 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 30866 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30874 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30880 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30898 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30904 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 30906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30918 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30926 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 30928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30932 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 30952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30968 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 30980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30982 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 30984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 30986 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 30990 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 30992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 30996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 30998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31006 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31010 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31020 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31032 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31044 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31064 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31068 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 31072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31086 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 31088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31096 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31120 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31142 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31144 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31158 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 31160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31168 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31194 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31198 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31212 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31220 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31230 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31234 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 31236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31238 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31240 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31242 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 31244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31246 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31252 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31260 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 31270 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 31278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31296 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31302 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31310 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31312 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 31314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31328 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31368 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 31376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31378 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31382 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31384 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 31386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31388 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31394 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31396 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31406 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31410 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31418 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31436 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31440 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31448 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31452 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31454 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31460 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 31484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31492 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31494 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31502 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31508 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31528 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31552 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31556 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31560 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31572 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31578 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31582 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31594 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31618 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31626 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31634 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31638 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31646 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31648 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31650 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31660 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31662 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 31664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31668 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31670 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31680 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 31690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31692 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31696 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31700 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31708 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31714 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31718 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31726 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 31728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31732 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31740 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31742 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 31744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31748 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31756 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31766 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31780 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31782 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31794 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31838 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31842 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31862 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31866 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31880 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31882 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 31896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31914 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 31916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31928 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 31940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 31964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 31972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31980 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 31982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 31990 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 31992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 31998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32016 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32018 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32028 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32032 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32054 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32060 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32062 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32064 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32074 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32084 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32100 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 32102 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32112 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32124 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32134 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32148 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32152 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32158 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32174 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32176 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32192 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32202 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32212 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32226 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32228 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32252 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32266 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32270 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32296 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32298 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 32308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32328 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32330 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32344 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32348 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32354 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32366 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 32368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32376 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32384 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32388 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32398 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32436 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32450 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32462 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32506 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 32514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32522 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 32524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32566 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32574 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32576 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32624 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32634 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 32636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32640 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32644 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32650 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 32652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32662 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32674 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32678 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32680 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32690 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32694 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32708 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 32720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32722 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32728 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32730 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32748 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32756 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32758 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32784 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32788 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32792 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32794 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 32796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32844 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32850 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 32852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32854 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32860 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32866 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 32878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32882 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32896 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32912 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32916 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 32926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 32958 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32962 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 32964 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 32966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32968 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 32970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 32988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 32994 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 32996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 32998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33002 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 33004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33012 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 33014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33020 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33044 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33078 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33096 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33108 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33120 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 33122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 33132 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33178 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33190 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33192 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33198 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33200 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33204 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33212 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 33214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33242 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33270 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33274 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 33276 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33280 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33324 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 33338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33348 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 33350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33370 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33382 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33386 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33410 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33418 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.06\n",
      "global step 33420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33438 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33448 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33460 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33474 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33476 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33494 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33506 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33512 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 33514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33522 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33530 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 33532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33538 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33540 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 33542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 33544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33552 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33566 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33570 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33574 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33576 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33586 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 33588 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33624 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 33626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33628 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33632 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33638 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 33640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33644 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33648 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 33650 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33652 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33660 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33670 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33672 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33684 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 33686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33690 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33698 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 33700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33704 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33708 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33710 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33724 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33732 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33744 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33748 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 33750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33768 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33772 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33780 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33786 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 33788 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33826 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33834 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33836 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33840 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33842 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33852 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 33854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33866 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33878 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33900 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33902 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33906 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 33908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 33918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33942 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 33954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 33956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33960 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 33962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33970 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 33972 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 33974 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 33976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33978 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33980 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 33982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 33988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 33992 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 33998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34004 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34012 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34022 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34024 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 34026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34032 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34038 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 34040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34060 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34070 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34088 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34108 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34116 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 34118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34152 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34158 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 34162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34176 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34186 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34202 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34206 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 34208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34218 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34222 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34226 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34232 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34234 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34244 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34258 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34270 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34274 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34298 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34300 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34302 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34310 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34312 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34322 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34330 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 34332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34346 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34362 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 34364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 34368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34378 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 34380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34398 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34404 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34408 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34414 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34438 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34454 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34470 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34474 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34478 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 34480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34488 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34504 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34532 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34542 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34544 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34552 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34560 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34562 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 34564 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34566 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34568 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34572 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 34574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34588 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34596 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34642 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34648 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34650 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34660 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34662 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34668 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34670 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34672 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34680 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34694 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34696 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 34698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34708 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34712 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34718 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34724 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 34726 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34732 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34744 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34758 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34764 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34776 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 34780 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 34782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34790 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 34792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34808 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34812 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 34814 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34818 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34828 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 34830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34834 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34860 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34874 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34896 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 34898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34900 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34924 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34926 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34934 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34936 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34948 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34950 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 34952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 34972 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 34974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 34978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 34982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34984 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 34986 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 34988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 34994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 34998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35012 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 35014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35024 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35028 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35034 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35044 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35056 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35060 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35068 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35070 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35084 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 35086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35090 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35092 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35100 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 35102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35106 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35110 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35120 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35122 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35124 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35142 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35162 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 35192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35200 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35210 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 35212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35238 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35246 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35248 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35258 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35262 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35276 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35284 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35286 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35292 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35322 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35324 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35326 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35352 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35354 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35364 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35368 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35370 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35376 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35382 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35388 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35392 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35396 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 35398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35428 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35430 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35438 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35460 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35464 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 35466 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35472 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35480 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 35482 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35490 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35498 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35500 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35510 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35536 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35538 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35552 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35562 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35572 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35574 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35580 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35582 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35584 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35586 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35588 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35596 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 35598 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 35604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35606 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35618 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35620 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35624 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35628 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35634 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35656 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35668 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35676 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35682 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35686 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35694 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35708 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 35710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35716 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35736 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 35738 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 35772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35774 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35788 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35792 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 35794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35796 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 35810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35812 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35814 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35818 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 35820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35826 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35840 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35842 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35850 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35868 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35900 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35902 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 35904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35908 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35920 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 35922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 35924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35926 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35940 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35980 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 35982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 35986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 35988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 35992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 35994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 35996 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 35998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36012 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 36016 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36024 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 36026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36030 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36034 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36038 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36040 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36044 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36046 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36052 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36064 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36072 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 36074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36080 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36082 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36090 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 36092 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36098 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36100 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36104 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36118 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36120 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36122 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36130 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36152 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36162 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 36164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36180 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36182 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 36184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 36192 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36198 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36204 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36206 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36212 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 36222 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36224 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 36226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36242 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 36244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36250 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36268 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36270 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36296 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36302 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36318 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36322 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36328 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36332 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 36334 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36364 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 36366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36370 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36372 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36376 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 36378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36382 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36386 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 36398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 36428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36432 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36438 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36442 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36470 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 36472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36474 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36482 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36484 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36486 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36490 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36498 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36502 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 36504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36506 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 36542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36556 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36568 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36572 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36578 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36580 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36592 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36600 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36602 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36604 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36606 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36626 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 36628 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 36634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36648 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36650 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36670 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36690 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36696 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 36698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36704 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36706 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36732 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 36784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36790 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36820 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 36822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36838 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 36840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36854 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36904 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36906 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36908 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36918 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 36924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36960 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 36970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 36986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 36990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 36992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 36994 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36996 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 36998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37000 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 37002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 37046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37050 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37054 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37072 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 37074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37082 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 37084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37086 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37104 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37108 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 37110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37124 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37132 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37136 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37146 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37150 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37154 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37158 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37166 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37168 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 37170 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37178 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37194 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37214 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37230 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37246 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37248 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 37252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37254 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37258 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37264 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37266 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37270 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37284 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37290 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37292 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37300 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37302 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37308 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 37310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37320 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37324 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 37334 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37336 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37352 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37366 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37384 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 37386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37388 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37400 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37408 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37412 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37416 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37436 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37454 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 37458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37460 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37490 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37502 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37506 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37508 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37522 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 37524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37550 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37552 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37568 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37578 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37580 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37584 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37586 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37594 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 37596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37600 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37602 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37608 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37612 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 37614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37618 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37626 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37652 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37662 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 37664 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 37666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37702 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37718 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37734 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37736 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37742 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 37744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37748 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37760 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 37762 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37768 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37780 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37796 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37798 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37818 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37836 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37846 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37848 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37856 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37862 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37866 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 37870 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37872 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 37874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37882 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37890 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 37892 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37906 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37914 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37928 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 37930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37958 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37962 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 37970 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 37990 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 37992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 37994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 37996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 37998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38014 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38016 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38018 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38020 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 38022 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38034 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 38036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38070 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 38072 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38074 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 38076 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 38078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38122 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38134 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38142 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38204 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38206 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38218 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 38220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38228 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38242 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38244 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38246 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38268 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38270 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38278 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38280 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 38282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38324 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38328 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38334 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38340 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38346 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38348 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 38350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38352 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38370 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38376 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38394 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38398 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 38400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38406 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38418 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 38420 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38424 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38462 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38474 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 38488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38504 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38506 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38536 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 38538 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38544 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38552 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 38554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38566 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 38568 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38570 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38578 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38588 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38602 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38612 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 38614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38622 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 38624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38640 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38642 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38644 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38666 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38686 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 38694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38698 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38730 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 38732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38734 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38738 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38740 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38744 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38748 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38758 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38764 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38766 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38778 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38780 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38782 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38784 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38786 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38790 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 38792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38820 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38832 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 38834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38840 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 38842 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38848 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 38850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38856 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38868 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38892 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38898 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 38900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38906 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38908 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38920 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38926 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38954 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38958 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 38960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38966 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 38970 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38974 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 38988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 38992 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 38994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 38996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 38998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39004 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39010 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 39012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39030 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 39032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39034 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39042 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39044 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39056 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39058 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39064 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39068 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39072 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39074 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39086 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39088 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 39090 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39094 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39100 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39104 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 39106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39110 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39114 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39122 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39132 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39142 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39144 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39150 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39162 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39214 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 39216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39222 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39228 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39230 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39262 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 39270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39302 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39304 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 39312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39314 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39324 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 39326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39338 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39388 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39398 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39414 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39420 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39428 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39438 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 39440 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 39442 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39444 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39468 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39472 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39482 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39488 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39494 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39502 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 39518 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39520 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39524 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39534 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39536 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39548 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39558 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39562 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39572 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 39574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39576 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39580 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39594 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39610 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 39612 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39618 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39626 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39632 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39640 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39660 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39674 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 39676 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39678 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39682 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39690 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39692 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39694 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39696 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 39698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39706 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 39708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 39724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39728 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39734 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39748 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39756 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39792 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39798 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39804 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39830 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39836 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39866 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39872 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39874 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39886 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 39888 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39900 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39926 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 39930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39934 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39958 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 39960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39974 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 39976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 39982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 39986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 39990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 39994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 39996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 39998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40004 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40014 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40034 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40036 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40040 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40056 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40072 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40080 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40082 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40088 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40100 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40108 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40118 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40126 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40132 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40134 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 40136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40142 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40148 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40152 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40156 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 40158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40164 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 40166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40180 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40210 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40230 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40242 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40254 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40266 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40270 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40276 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40278 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40280 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40306 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40310 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40330 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40336 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40338 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 40340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 40342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40364 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40368 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40378 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40382 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40386 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40398 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 40400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40402 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40404 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40408 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40416 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40444 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40466 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40488 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40490 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40494 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40506 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 40548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40552 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40554 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40556 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40564 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40584 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40594 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40596 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40602 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40604 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40606 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40618 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40620 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40622 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40634 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40640 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40648 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40662 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40668 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40670 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40680 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40690 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40708 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40720 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40726 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40728 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40740 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 40742 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 40754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40764 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40780 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40794 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40796 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40800 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 40802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40828 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 40862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40888 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40894 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40912 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40936 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40944 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 40946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40954 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 40960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40968 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40974 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 40976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 40978 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 40988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 40992 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 40994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 40996 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 40998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41002 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41006 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 41008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41024 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 41026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41068 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41076 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 41078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41086 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41088 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 41090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41092 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41114 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41116 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41134 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41152 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 41166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41170 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41186 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41190 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 41192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41212 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41226 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 41228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41256 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41276 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 41278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41280 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41282 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41300 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 41318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41322 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41328 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 41330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41358 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41368 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 41370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 41372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41374 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41398 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41400 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41412 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41420 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41424 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41450 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41454 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41456 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41458 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41466 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41482 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41484 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 41486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41502 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41508 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41510 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41532 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41552 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41568 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 41578 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41580 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 41582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41584 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41602 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 41604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41608 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41618 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41620 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41666 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41670 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 41672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41676 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41682 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41700 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 41702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41710 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41722 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41738 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41752 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41762 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41766 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 41784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41792 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 41794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41798 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41808 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 41810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41812 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 41814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41818 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41830 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41840 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41842 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41848 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41854 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41856 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41876 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 41878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41880 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41900 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41906 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 41908 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 41910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41926 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41946 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41956 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 41958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 41964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41966 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41968 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41970 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 41972 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 41982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 41990 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 41994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 41996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 41998 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42004 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42008 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42012 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42032 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 42034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42042 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42050 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42058 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42062 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42066 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42068 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42088 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42102 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 42104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42112 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42122 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 42124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42130 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42132 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 42134 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42146 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 42148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42152 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42160 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 42162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42166 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42168 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42180 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 42196 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42198 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42234 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42250 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42252 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 42254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42262 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42266 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42270 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42284 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42298 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42300 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42302 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42304 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42314 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42322 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42328 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42336 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42358 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42366 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42390 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42394 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 42402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42404 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42452 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42470 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42490 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42496 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42502 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42506 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42514 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42518 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42538 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42544 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 42546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42552 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 42554 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42568 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42572 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42576 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 42578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42584 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42588 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42594 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42596 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 42608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42622 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42624 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42626 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42628 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 42630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42644 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42648 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42666 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42674 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42688 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42690 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42692 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42694 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42700 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42708 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42726 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 42728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42730 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 42732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42736 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42748 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42764 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42768 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42772 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42774 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42794 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42798 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42800 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42812 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 42814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42830 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42834 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42846 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 42862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42882 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42886 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42910 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42924 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42930 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42938 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 42940 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 42942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42952 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42970 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 42976 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42980 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 42982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 42990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 42992 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 42994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 42996 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 42998 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43004 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43008 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 43020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43024 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43030 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 43032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43034 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43042 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43076 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43080 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43084 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43096 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43108 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 43110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43116 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43118 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 43120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43126 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43140 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43142 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43168 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43186 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43204 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43210 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43212 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43218 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43224 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 43226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43228 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43244 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43248 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43252 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43266 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43272 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43292 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43300 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43302 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43322 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 43334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43338 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43346 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43354 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43358 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43360 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43364 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43386 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43396 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43414 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43422 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43428 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 43432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43444 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 43446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43462 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43466 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43468 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43472 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43490 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43492 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43494 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43502 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43540 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43550 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43560 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 43562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43570 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43582 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43588 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43606 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43616 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43632 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 43638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43644 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43672 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43674 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43682 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43684 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43692 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43696 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43744 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43746 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43748 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43754 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43762 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43764 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 43772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43778 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 43780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43794 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43796 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43808 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43824 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43830 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43836 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43840 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 43844 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43858 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43870 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43876 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43890 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43912 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43914 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43922 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43926 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43946 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43952 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43956 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 43958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43960 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 43962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43970 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43972 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 43974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43980 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 43982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 43988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 43992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 43994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 43998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44014 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44018 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44024 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44026 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44036 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44042 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 44050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44052 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 44054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44056 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44060 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44066 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44080 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44100 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44108 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44116 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44118 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44120 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44128 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44130 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44140 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44152 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44158 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44166 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44176 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44178 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44190 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44206 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44212 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44224 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 44256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44258 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44260 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44264 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44270 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44276 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44280 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 44282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44288 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44292 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44294 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44298 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44300 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44310 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44312 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44318 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44322 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44324 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44330 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44360 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 44362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44364 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44370 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44374 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44382 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44394 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44426 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44432 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44440 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44450 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44452 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44458 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 44460 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 44462 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44468 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44474 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44480 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 44482 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44504 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44508 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44518 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44532 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44534 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44538 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44558 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44568 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44570 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44574 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44582 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44584 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44590 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44596 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44624 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44628 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44632 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44636 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44638 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44648 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44652 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44658 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44666 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 44668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44672 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44680 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44684 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44686 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44700 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44706 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44708 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44728 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44748 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44770 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44778 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44782 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44788 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44790 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 44792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44814 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44828 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44840 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44842 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44854 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44856 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44872 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 44874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44878 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44888 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 44890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44892 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44894 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44912 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44914 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 44916 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44926 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44938 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44940 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44952 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 44956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44958 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 44962 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44982 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44986 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 44988 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 44990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 44992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 44996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 44998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45002 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45018 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45036 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45038 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45056 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45060 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 45080 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45084 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 45086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45090 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45092 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45114 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45118 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45120 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45122 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45124 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45126 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45136 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45142 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45144 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45154 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45156 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45178 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45186 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45198 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45206 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45220 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45222 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45236 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45246 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 45248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45250 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45252 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45254 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45256 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 45286 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 45288 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 45290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45300 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 45302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45328 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45338 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45352 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45358 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45360 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45364 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45368 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45372 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45380 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45386 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45404 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45408 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45414 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45428 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45438 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 45440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45442 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45448 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45454 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45464 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45470 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 45492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45514 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45524 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45530 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45532 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45536 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45546 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45550 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45564 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 45566 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45568 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 45570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45584 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45588 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45594 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45604 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45624 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45632 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45634 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45636 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45642 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45668 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45670 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 45672 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45676 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45678 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45684 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45686 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45688 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 45690 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 45698 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45704 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45706 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45710 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45716 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45720 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45736 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45738 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45758 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 45760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45766 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45774 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45792 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45808 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45812 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45818 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 45820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45822 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45824 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45826 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 45828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45834 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45840 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45842 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45852 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45856 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45864 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45866 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45872 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45878 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45884 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45902 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 45904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45906 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 45908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45910 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45920 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45922 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45932 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45936 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 45944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45948 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45950 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 45952 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45954 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45966 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45968 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45970 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 45972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45978 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 45984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45988 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 45990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 45994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 45998 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46000 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46012 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46026 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46030 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46034 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46040 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 46042 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46052 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46058 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46076 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46080 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46088 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46090 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46092 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46098 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46102 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46104 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46108 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 46110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46118 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 46120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46126 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46140 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46142 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46144 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 46146 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 46148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46174 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 46176 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46192 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46196 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46198 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46200 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 46202 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46204 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46218 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46222 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46226 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46230 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46232 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46248 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46254 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46258 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46270 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46272 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46282 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46284 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46300 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 46316 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46336 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46342 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46344 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 46346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46354 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46358 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46360 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46362 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46368 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46384 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46388 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46408 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46410 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46412 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46420 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46422 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46430 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46436 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46446 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46450 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 46452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46470 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46486 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46488 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46494 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46516 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46518 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 46522 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46524 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46530 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46540 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46554 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46574 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46578 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46584 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46588 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46590 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46598 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46612 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46616 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46620 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46622 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46628 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46634 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46646 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46648 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46650 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46656 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46658 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46662 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46670 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46682 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 46684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46690 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46694 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 46696 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 46698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46700 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46704 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46706 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46708 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 46728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46742 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46756 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46760 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46764 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46766 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46790 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46806 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46808 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46812 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46816 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46828 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46832 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46834 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46848 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46854 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46860 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46862 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46876 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46888 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46892 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46896 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 46898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46904 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46914 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46916 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46920 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46926 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46928 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 46932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 46934 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 46936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46952 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 46954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46956 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46958 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 46966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46970 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 46982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 46986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 46992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 46994 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46996 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 46998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47006 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47010 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47012 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47016 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47020 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47022 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47028 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47030 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47036 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47040 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47042 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47050 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47054 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47056 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47058 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47076 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47084 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47086 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47088 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47098 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47110 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47116 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47124 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 47126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47128 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47130 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47132 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47138 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 47140 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47146 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47152 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47162 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47166 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47168 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47174 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47176 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47180 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47182 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47190 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47192 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47194 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47196 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47202 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47206 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47208 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47210 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47214 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47220 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47232 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47236 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47238 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47240 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47246 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47250 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47262 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47272 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47274 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47292 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47298 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47308 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47310 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47314 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47326 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47330 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47332 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47336 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 47338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47342 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 47346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47350 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47358 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47362 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47366 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47380 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47382 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47390 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47394 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47408 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47428 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47446 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47452 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47464 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47474 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47482 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47484 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47508 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47514 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47516 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47522 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47546 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 47552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47564 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47576 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47578 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47584 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47606 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47618 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47630 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47634 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47636 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47640 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47646 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47650 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47654 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47664 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47666 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47672 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47678 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47684 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47686 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47698 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47704 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 47706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47712 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47714 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47720 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47728 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47738 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 47740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47752 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47754 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 47758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47764 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47770 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 47772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47776 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47786 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47790 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47794 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47802 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47808 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47810 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47820 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47822 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47824 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47826 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47828 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47832 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47838 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47840 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47842 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47848 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47850 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47858 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47860 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47864 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47872 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 47874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47878 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47880 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47882 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47886 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 47888 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47890 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47892 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47900 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47908 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47910 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47928 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47938 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47942 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47946 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47950 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47952 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47956 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47960 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47962 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 47964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47968 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 47970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 47978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47980 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 47982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 47986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 47990 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 47992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47994 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 47996 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 47998 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48004 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48006 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48014 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48016 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48018 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48020 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48024 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48026 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48036 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48046 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48048 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48050 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48052 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48056 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48058 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48060 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48068 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48074 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48090 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48092 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48102 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48104 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48106 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48148 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48160 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48166 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48168 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 48170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48172 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48178 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48184 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48188 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48192 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48202 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48204 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48206 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48208 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48210 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48214 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48228 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48234 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48246 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48250 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48254 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48272 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48274 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48278 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48290 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48306 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48308 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 48310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48316 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48318 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 48320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48324 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48330 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48336 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48340 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48342 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48344 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48348 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48358 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48366 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48370 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48372 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 48376 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48378 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48380 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 48382 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48384 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48386 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48390 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48392 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48400 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48402 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48408 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48416 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48428 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48434 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48444 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48446 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 48448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48456 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48464 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48468 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48474 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48476 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48480 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48486 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48488 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48498 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48500 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48502 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48504 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 48506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48508 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48518 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48520 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48524 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48528 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48532 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48536 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48538 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48542 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48544 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48546 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48550 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48558 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48560 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48564 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48574 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 48582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48584 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48590 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 48592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48606 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48618 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48620 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 48622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48632 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48634 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48638 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48644 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48646 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48650 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48658 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48662 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48670 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48672 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48680 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48684 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48688 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48700 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48702 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48706 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48708 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48710 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48712 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48724 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48732 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48734 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48736 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48742 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48754 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48758 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48762 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48768 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48772 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48778 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48784 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 48788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48790 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48792 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48794 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48796 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48814 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48820 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48826 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48854 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48856 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48860 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48868 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48874 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48882 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48886 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48904 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48914 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 48916 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48920 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48942 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48944 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48948 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48956 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 48958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48964 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48966 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48968 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 48970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48972 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48976 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 48980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 48984 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 48988 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 48992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 48994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 48996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 48998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49004 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49008 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49010 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49012 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 49014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49016 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49018 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49020 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49024 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49026 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49028 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 49030 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49034 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49044 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49048 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 49050 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49052 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49056 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49060 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49066 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49068 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49070 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49080 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49086 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49090 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49094 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49100 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49102 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49104 learning rate 0.0000 step-time 0.00 perplexity 1.14 loss 0.13\n",
      "global step 49106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49114 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49120 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49124 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49126 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49132 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49140 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49146 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49152 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49158 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49162 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49164 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49168 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 49170 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49176 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49178 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49180 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49186 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49192 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49194 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49198 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 49200 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49204 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49210 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49214 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49222 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49234 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49244 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49248 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49250 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 49252 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49258 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49260 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49262 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49268 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49272 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49274 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49278 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49280 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49282 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49296 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49298 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 49300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49302 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49304 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49310 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49312 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49314 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 49318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49320 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49322 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49326 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49344 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 49346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49352 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49354 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49356 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49368 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49370 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 49372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49376 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49384 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49388 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49394 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49396 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49398 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49400 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49404 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 49406 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49408 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49414 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49418 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49420 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49440 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49444 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49446 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49448 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49452 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49456 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49464 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49474 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49478 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49480 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49482 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49486 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49488 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49492 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49494 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49496 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49500 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49504 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49506 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49510 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49512 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49520 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49522 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49530 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49532 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49538 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49542 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49544 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 49546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49564 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49566 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49580 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49584 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49602 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 49612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49614 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49620 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49624 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49626 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49634 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49638 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49640 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49642 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49650 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 49652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49654 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49662 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49668 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49670 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49672 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49674 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49684 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49688 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49692 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49696 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49698 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49704 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49706 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49708 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49722 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49742 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49746 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49748 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49750 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49752 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49758 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49760 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49764 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49770 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49774 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49782 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49784 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49788 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49790 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49796 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49802 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49804 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49810 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49812 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 49818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49826 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49834 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49836 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49838 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49846 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49850 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49854 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49858 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49860 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49862 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49864 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49866 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49870 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49874 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49878 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49888 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49892 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49896 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49898 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49900 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49902 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49906 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49912 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49914 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49918 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49922 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49930 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49932 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49940 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49944 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49946 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49948 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49950 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49952 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49958 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49960 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49962 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 49964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49968 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 49970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49972 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 49974 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 49980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 49986 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 49990 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 49994 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 49996 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 49998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50000 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50002 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50006 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50008 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 50024 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50026 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50032 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50034 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50038 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50046 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50052 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50058 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50062 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50064 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50072 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50076 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50078 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50082 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50088 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50090 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50092 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50100 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50104 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50106 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 50108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50110 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50114 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50118 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50120 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 50122 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50124 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50130 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50134 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50138 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50140 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50142 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50150 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50156 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50158 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50160 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50164 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 50166 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50170 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50172 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50174 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50178 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50182 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50184 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50188 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50190 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50192 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50194 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50206 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50210 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50212 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50216 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50218 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50220 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50224 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50226 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 50230 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 50232 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50234 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50238 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50250 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50252 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50254 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50256 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50258 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50260 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50266 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50270 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50278 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50280 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50286 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50288 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50298 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50300 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50308 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50312 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50316 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50318 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50320 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50322 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50326 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50330 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50332 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50334 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50344 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50346 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50348 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50352 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50356 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50358 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 50360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50364 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50368 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50370 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50378 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50380 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50384 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50386 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50388 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50390 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50392 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50394 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50398 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50408 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50410 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50412 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50414 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50416 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50418 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50420 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50422 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50426 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50430 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50432 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50434 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 50436 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50438 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50442 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50444 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50452 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50454 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50456 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50460 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50462 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50464 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50468 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50474 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50476 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50478 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50480 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 50482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50486 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50488 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50490 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50504 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 50506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50512 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50526 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50528 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 50530 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 50532 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 50534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50538 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50546 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 50548 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50552 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50556 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50560 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50562 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50564 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50570 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50574 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50580 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50582 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50584 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50586 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50588 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50590 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 50592 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50594 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50596 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50598 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50600 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50602 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50604 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50608 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50610 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50612 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50624 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50626 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50634 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50638 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 50640 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 50642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50648 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50650 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50652 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50660 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50662 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50664 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50668 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50670 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50674 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50678 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50682 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50684 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50686 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50690 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50700 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 50702 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50706 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50708 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50710 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50718 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50720 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50722 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50726 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50734 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50748 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50750 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50754 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 50756 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50764 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50768 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50770 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50772 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50774 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50780 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50784 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50786 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50788 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50798 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50800 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50806 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50808 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50812 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50816 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50818 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50820 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50826 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50828 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50830 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50834 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50838 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50840 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50842 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50846 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 50848 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50850 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50860 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50862 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50874 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50880 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50882 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50884 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50888 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50892 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50894 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50896 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 50898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50900 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50902 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50904 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50908 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50910 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50912 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50914 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50916 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50918 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50920 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50922 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50924 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50926 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50928 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50930 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50934 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50936 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50938 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50942 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50944 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50946 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 50948 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50952 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50954 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50956 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50960 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50962 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 50964 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50968 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50970 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50974 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 50976 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50978 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50980 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50982 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 50984 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 50986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50988 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 50990 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 50994 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 50996 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 50998 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51000 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51004 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51014 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51016 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51020 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51022 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51024 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51026 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51032 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51034 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51040 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51042 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51044 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51046 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51048 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 51052 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51054 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51056 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51058 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51060 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51062 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51064 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51066 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51070 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51072 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51076 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51078 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51080 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51082 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51084 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51086 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51090 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51096 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51098 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51102 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51104 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51106 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51108 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51110 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51112 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51114 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51116 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51118 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51122 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51124 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51126 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51128 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51130 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51132 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51136 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51138 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51144 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51146 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51148 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51150 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51152 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51154 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51156 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51158 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 51160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51164 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51168 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51172 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51176 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51180 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51182 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51184 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51186 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51188 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51194 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51196 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 51198 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51200 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51202 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51204 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51206 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51208 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51212 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51214 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51216 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51218 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51220 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51224 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51228 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51230 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51232 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51234 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51236 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51240 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51242 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51248 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51250 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51254 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 51258 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51260 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51264 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51266 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51268 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51270 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51272 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51276 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51280 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51282 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51284 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51286 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51288 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51290 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 51292 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51294 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51298 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51300 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51302 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51306 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51308 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51312 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51314 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51316 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51318 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51320 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51324 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51326 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51328 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51330 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51332 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51334 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51336 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51338 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51340 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51346 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51348 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51350 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51354 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51356 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51358 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51360 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51364 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51372 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51380 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51382 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51384 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51386 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51388 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51392 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51394 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51396 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51398 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 51400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51402 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51404 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51406 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51408 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51410 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51412 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51414 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51416 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51420 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51424 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51428 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51430 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 51432 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51434 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51436 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51438 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51440 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51442 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51444 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51448 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51450 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51458 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51460 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51462 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 51464 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51466 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51470 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51472 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51476 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51482 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51484 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51486 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51490 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51496 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51498 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51502 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51504 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51506 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51508 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51512 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51514 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51516 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51518 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51520 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51524 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 51526 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51528 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51530 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51532 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51534 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51538 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51540 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51542 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51546 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51548 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51550 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51554 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51558 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51560 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51562 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51564 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51568 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51570 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51572 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51574 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 51576 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51578 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51580 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51582 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51584 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51586 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51588 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51590 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51592 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51594 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51596 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51598 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51600 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51602 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51604 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51606 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51610 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51612 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51614 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51616 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51618 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51622 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51624 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51626 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51628 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51630 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51632 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51634 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 51636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51642 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51648 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51652 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51656 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51658 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51660 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51664 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51666 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 51670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51672 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 51674 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51676 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51678 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51680 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51684 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51690 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51694 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51702 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51704 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51706 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51708 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51710 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51714 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51716 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51718 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51724 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51726 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51728 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51730 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51732 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51734 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51736 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51738 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51740 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51744 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51746 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51754 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51756 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51760 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51762 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51764 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 51766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51768 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51772 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51776 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51778 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51782 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51786 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51788 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51790 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51794 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51796 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51800 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51804 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51814 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51820 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51822 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51826 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51830 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51832 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51834 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51840 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51842 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 51844 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51848 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51850 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51852 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51854 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51858 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51862 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51864 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51866 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51868 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51870 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51872 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51874 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 51876 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51878 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51880 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51882 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 51884 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51886 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51888 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51890 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51892 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51894 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51896 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51898 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51900 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 51902 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51904 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51906 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51908 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51910 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51912 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51914 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51916 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51918 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51920 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51922 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51924 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51926 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51928 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51930 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51932 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51934 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51936 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51938 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51940 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51942 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51944 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51946 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51948 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 51950 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51952 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51954 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51956 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51958 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51960 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51962 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51964 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51966 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51968 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51970 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 51972 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51974 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51976 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 51978 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51980 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 51982 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51984 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51986 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51988 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51990 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 51992 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 51994 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 51996 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 51998 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52000 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52002 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52004 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52006 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52008 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52010 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52012 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52014 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52016 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52018 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52020 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52022 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52024 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 52026 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52028 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52030 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52032 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52034 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52036 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52038 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52040 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52042 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52044 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52046 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52048 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52050 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52052 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52054 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52056 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52058 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52060 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52062 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52064 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52066 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52068 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52070 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52072 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52074 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52076 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52078 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52080 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 52082 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52084 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52086 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52088 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52090 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52092 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52094 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52096 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52098 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52100 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52102 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52104 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52106 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52108 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52110 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52112 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52114 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52116 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52118 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 52120 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52122 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52124 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52126 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52128 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52130 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52132 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52134 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52136 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52138 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52140 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52142 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52144 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52146 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52148 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52150 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52152 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52154 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52156 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52158 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52160 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52162 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52164 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52166 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52168 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52170 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52172 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52174 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52176 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 52178 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52180 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 52182 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52184 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52186 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52188 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52190 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52192 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52194 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52196 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52198 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52200 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52202 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52204 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52206 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52208 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52210 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52212 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52214 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52216 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52218 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52220 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52222 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52224 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52226 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52228 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52230 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52232 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52234 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52236 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52238 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52240 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52242 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52244 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52246 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52248 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52250 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52252 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52254 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52256 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52258 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52260 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52262 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52264 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52266 learning rate 0.0000 step-time 0.00 perplexity 1.07 loss 0.07\n",
      "global step 52268 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52270 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52272 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 52274 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52276 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52278 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52280 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52282 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52284 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52286 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 52288 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52290 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52292 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52294 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52296 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52298 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52300 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52302 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52304 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52306 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52308 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52310 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52312 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52314 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52316 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52318 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52320 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52322 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52324 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52326 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52328 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52330 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52332 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52334 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52336 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52338 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52340 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52342 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52344 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52346 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52348 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52350 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52352 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52354 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52356 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52358 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52360 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52362 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52364 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52366 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52368 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52370 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52372 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52374 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52376 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52378 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52380 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52382 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52384 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52386 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.13\n",
      "global step 52388 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52390 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52392 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52394 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52396 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52398 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52400 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52402 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52404 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52406 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 52408 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52410 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52412 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52414 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52416 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52418 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52420 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52422 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52424 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52426 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52428 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.07\n",
      "global step 52430 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52432 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52434 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52436 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52438 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52440 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52442 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52444 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52446 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52448 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52450 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52452 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52454 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52456 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52458 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52460 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52462 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52464 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52466 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52468 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52470 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52472 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52474 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52476 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52478 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52480 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52482 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52484 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52486 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52488 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52490 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52492 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 52494 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52496 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52498 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52500 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52502 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 52504 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52506 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52508 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52510 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52512 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52514 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52516 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52518 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52520 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52522 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52524 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52526 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52528 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52530 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52532 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52534 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52536 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52538 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52540 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52542 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52544 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52546 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52548 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52550 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52552 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52554 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52556 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52558 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52560 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52562 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52564 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52566 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52568 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52570 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52572 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52574 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52576 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52578 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52580 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52582 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52584 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52586 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52588 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52590 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52592 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52594 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52596 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52598 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52600 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52602 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 52604 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52606 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52608 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52610 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52612 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52614 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52616 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52618 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52620 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52622 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52624 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52626 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52628 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52630 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52632 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52634 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52636 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52638 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52640 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52642 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52644 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52646 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52648 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52650 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52652 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52654 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52656 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52658 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52660 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52662 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52664 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52666 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52668 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52670 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52672 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52674 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52676 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52678 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52680 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52682 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52684 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52686 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52688 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52690 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52692 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52694 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52696 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52698 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 52700 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52702 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52704 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52706 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52708 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52710 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52712 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52714 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52716 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52718 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52720 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52722 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52724 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52726 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52728 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52730 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52732 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52734 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52736 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52738 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52740 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52742 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52744 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52746 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52748 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52750 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52752 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52754 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.12\n",
      "global step 52756 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52758 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52760 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52762 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52764 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52766 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52768 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52770 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52772 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52774 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52776 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52778 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52780 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52782 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52784 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52786 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52788 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52790 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52792 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52794 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52796 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52798 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52800 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52802 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52804 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52806 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52808 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52810 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52812 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52814 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52816 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52818 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52820 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52822 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52824 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52826 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52828 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52830 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52832 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52834 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52836 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52838 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52840 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52842 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52844 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52846 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52848 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52850 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52852 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52854 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52856 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52858 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.08\n",
      "global step 52860 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52862 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52864 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52866 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52868 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52870 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52872 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52874 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.09\n",
      "global step 52876 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52878 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52880 learning rate 0.0000 step-time 0.00 perplexity 1.08 loss 0.08\n",
      "global step 52882 learning rate 0.0000 step-time 0.00 perplexity 1.13 loss 0.12\n",
      "global step 52884 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n",
      "global step 52886 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52888 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52890 learning rate 0.0000 step-time 0.00 perplexity 1.09 loss 0.09\n",
      "global step 52892 learning rate 0.0000 step-time 0.00 perplexity 1.12 loss 0.11\n",
      "global step 52894 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52896 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.10\n",
      "global step 52898 learning rate 0.0000 step-time 0.00 perplexity 1.10 loss 0.10\n",
      "global step 52900 learning rate 0.0000 step-time 0.00 perplexity 1.11 loss 0.11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from lib import data_utils, model_utils\n",
    "from configs import model_config\n",
    "\n",
    "\n",
    "#새로운 tensorflow 세션을 생성합니다 이후 sess 라는 이름으로 호출합니다\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    print(\"Created model with fresh parameters.\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #vacab파일의 경로를 정의합니다. 여러 모델의 테스트를 위해서 사전 크기를 파일명뒤에 명시적으로 표시합니다\n",
    "    #예를들어 8000 사이즈의 vovab 파일은 vocab8000.in 입니다.\n",
    "    vocab_path = os.path.join(config.data_dir, 'vocab%d.in' % config.vocab_size)\n",
    "\n",
    "    #학습 데이터의 경로를 정의합니다. 여러 모델의 테스트를 위해서 사전 크기를 파일명뒤에 명시적으로 표시합니다\n",
    "    #예를들어 8000 사이즈의 사전으로 전처리된 학습 데이터는 chat_ids8000.in 입니다.\n",
    "    train_data_path = os.path.join(config.data_dir, 'chat_ids%d.in' % config.vocab_size)\n",
    "\n",
    "    #사전 파일을 로드합니다\n",
    "    #vovab.get(word) 형태로 해당 워드에 맞는 사전 index 값을 반환합니다\n",
    "    #vocab_rev(index) 향태로 해당 index에 맞는 워드를 반환 합니다\n",
    "    vocab, vocab_rev = data_utils.load_vocabulary(vocab_path)\n",
    "\n",
    "    #학습 데이터를 로드합니다.\n",
    "    #[[[]]] 학습데이터는 3차원 리스트의 형태로 이루어지며\n",
    "    # [\n",
    "    #   [\n",
    "    #       [2,34,523,5,3,2,5,6,32],\n",
    "    #       [2,1,52,1,2,2,5,6,3],\n",
    "    #\t],\n",
    "    #\t[\n",
    "    #       [2,34,523,5,3,2,5,6,32],\n",
    "    #       [2,1,52,1,2,2,5,6,3]\n",
    "    #\t]\n",
    "    # [\n",
    "    # 커스터마이징이 필요한 경우가 아니면 기존의 구현을 활용하는것을 추천합니다.\n",
    "\n",
    "    train_set = data_utils.read_data_chat(train_data_path, config)\n",
    "    # print(train_set[0])\n",
    "\n",
    "\n",
    "    #초기 변수를 세팅합니다.\n",
    "    step_time, loss_val = 0.0, 0.0\n",
    "    current_step = 0\n",
    "    perplexity = 10000.0\n",
    "    previous_losses = []\n",
    "\n",
    "    \n",
    "    while current_step < config.max_epoch and not forward_only:\n",
    "        #스텝당 계산 시간을 검출하기 위해서 현재 시간을 기록하고\n",
    "        start_time = time.time()\n",
    "        #다중 버킷 모델 NMT 관련 모델에 관련된 옵션으로 여기서는 0으로 처리 합니다\n",
    "        bucket_id = 0\n",
    "\n",
    "        #데이터 유틸리티 함수를 이용하여 이번 스탭에서 모델 계산에 필요한 모든 배치 데이터를 가져 옵니다.\n",
    "        step_encoder_inputs, step_encoder_inputs_length, step_decoder_inputs, step_decoder_inputs_length, step_target_weights = (data_utils.get_batch(train_set[bucket_id], config))\n",
    "\n",
    "        #seq2seq 모델에 모든 데이터와 loss 값을 기반으로 경사도를 계산하고\n",
    "        #옵티마이저가 loss를 줄이는 방향으로 step마다 모델의 파라메터를 업데이트 합니다.\n",
    "        _, step_loss, _, _, enc_embedding, dec_embedding = step(sess, step_encoder_inputs, step_encoder_inputs_length, step_decoder_inputs, step_decoder_inputs_length, step_target_weights)\n",
    "\n",
    "        #모델의 학습 상황을 확인하기 위해서 스탭당 시간을 계산하고\n",
    "        step_time += (time.time() - start_time) / 100\n",
    "        #loss의 변화를 합산 합니다.\n",
    "        loss_val += step_loss / 100\n",
    "        current_step += 1\n",
    "\n",
    "        #100 step 마다 아래의 처리를 합니다\n",
    "        #if current_step % 2 == 0:\n",
    "        if current_step % 2 == 0:\n",
    "            # loss *= config.max_state_length \t\t# Temporary purpose only\n",
    "            # loss 를 가지고 perplexity 값을 계산합니다.\n",
    "            perplexity = math.exp(loss_val) if loss_val < 300 else float('inf')\n",
    "            print(\"global step %d learning rate %.4f step-time %.2f perplexity %.2f loss %.2f\" %\n",
    "                        (global_step.eval(), learning_rate.eval(), step_time, perplexity, loss_val))\n",
    "            #스탭에서 두번 이상 연속으로 loss 값이 줄어들지 못한경우\n",
    "            if len(previous_losses) > 2 and loss_val > max(previous_losses[-2:]):\n",
    "                #learning_rate를 감소시켜 모델의 학습을 용이하게 합니다\n",
    "                sess.run(learning_rate_decay_op)\n",
    "            #100 step 당 로스를 시계열로 기록해 둡니다.\n",
    "            previous_losses.append(loss_val)\n",
    "\n",
    "            #100 step 마다 모델을 저장합니다.\n",
    "            #checkoint_path = os.path.join(config.model_dir, \"model.ckpt\")\n",
    "            #model.saver.save(sess, checkoint_path, global_step=model.global_step)\n",
    "            step_time, loss_val = 0.0, 0.0\n",
    "            sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
