{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, GRUCell, MultiRNNCell\n",
    "from tensorflow.contrib.rnn.python.ops.rnn_cell import _linear\n",
    "\n",
    "from lib import data_utils, model_utils\n",
    "from configs import model_config\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def __init__(self, config, use_lstm=True, forward_only=False,  attention=False ,sess=None):\n",
    "\n",
    "config = model_config.Config()\n",
    "use_lstm=True \n",
    "forward_only=True\n",
    "attention=True\n",
    "\n",
    "#config에서 모델의 설정값을 가져옵니다.\n",
    "vocab_size = config.vocab_size\n",
    "enc_hidden_size = config.enc_hidden_size\n",
    "enc_num_layers = config.enc_num_layers\n",
    "dec_hidden_size = config.dec_hidden_size\n",
    "dec_num_layers = config.dec_num_layers\n",
    "batch_size = config.batch_size\n",
    "attention = attention\n",
    "\n",
    "\n",
    "#학습 과정에서 가변 learning_rate 를 적용하기 위해서 tf.Variable 타입으로 선언합니다\n",
    "learning_rate = tf.Variable(float(config.learning_rate), trainable=False)\n",
    "#아래 op는 learning step 에서 두번이상 loss 가 증가헀을경우 learning_rate_decay_factor 를 곱해서\n",
    "#기본값인 learning_rate_decay_factor = 0.99의 경우 본 op가 한번 실행될때마다 learning_rate 가 1% 감소시키는 효과를 가저옵니다\n",
    "learning_rate_decay_op = learning_rate.assign(\n",
    "    learning_rate * config.learning_rate_decay_factor)\n",
    "#global_step 역시 학습 과정에서 계속 증가하여야 하는 값이므로 tf.Variable 형태로 선언하고 0으로 초기화합니다\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "max_gradient_norm = config.max_gradient_norm\n",
    "buckets = config.buckets\n",
    "\n",
    "#RNN의 내부 구조를 LSTM과 GRU중 선택으로 분기합니다.\n",
    "if use_lstm:\n",
    "    single_cell1 = LSTMCell(enc_hidden_size)\n",
    "    single_cell2 = LSTMCell(dec_hidden_size)\n",
    "else:\n",
    "    single_cell1 = GRUCell(enc_hidden_size)\n",
    "    single_cell2 = GRUCell(dec_hidden_size)\n",
    "\n",
    "#multi layers 구조의 RNN 처리를 위한 부분 입니다. tensor 1.0 ~ 1.1 구간에서 해당 구현에 대한 이슈가 존재하여 본 예제에서는\n",
    "#single layers의 구현을 가정하고 진행하겠습니다.\n",
    "#seq2seq 모델의 경우 2 layers 부터 학습이 매우 어려워지는 경향을 보이며 4 layers 이상은 학습이 거의 되지 않는다 라는 경험적인 의견이 많습니다.\n",
    "enc_cell = MultiRNNCell([single_cell1 for _ in range(enc_num_layers)])\n",
    "dec_cell = MultiRNNCell([single_cell2 for _ in range(dec_num_layers)])\n",
    "\n",
    "#인코딩 셀과 디코딩 셀을 self로 클래스 변수로 잡아 클래스내 다른 함수에서 이를 사용할것 입니다.\n",
    "encoder_cell = enc_cell\n",
    "decoder_cell = dec_cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def _init_data(self):\n",
    "# encoder_inputs의 placeholder로 들어오는 2차원 matrix 예시 입니다.\n",
    "#[\n",
    "# [36, 6, 36, 6, 14, 5, 13, 35, 739, 41, 24, 103, EOS_ID],\n",
    "# [3, 5, 13, 956, 3, 227, EOS_ID, GO_ID, 142, 331, 4, 17, 8, 112, 6, 155, 3, EOS_ID] , ...\n",
    "#]\n",
    "\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name=\"encoder_inputs\")\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name=\"encoder_inputs_length\")\n",
    "\n",
    "# decoder_inputs의 placeholder로 들어오는 2차원 matrix 예시 입니다.\n",
    "#[\n",
    "# [GO_ID, 5, 15, 33, 12, 2021, 3,2274,EOS_ID],\n",
    "# [GO_ID, 142, 331, 4, 17, 8, 112, 6, 155, 3, EOS_ID] , ...\n",
    "#]\n",
    "\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name=\"decoder_inputs\")\n",
    "decoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name=\"decoder_inputs_length\")\n",
    "\n",
    "#np.array 타입의 슬라이싱을 이용하여 decoder_inputs의 GO 심볼이 위치하는 부분을 제거합니다\n",
    "decoder_targets = decoder_inputs[1:, :]\n",
    "\n",
    "#input 과 output 데이터를 버킷에 사이즈에 맞춰서 잘라냅니다\n",
    "#기본값은 \tmodel.config = buckets = [(8, 15)]로 이 경우에는 input의 경우 순서열의 최대 길이가 8 output의 경우 최대길이가 15로 잘리게 됩니다\n",
    "temp_encoder_inputs = encoder_inputs[:buckets[-1][0], :]\n",
    "encoder_inputs2 = temp_encoder_inputs\n",
    "temp_decoder_inputs = decoder_inputs[:buckets[-1][1], :]\n",
    "decoder_inputs2 = temp_decoder_inputs\n",
    "\n",
    "# cross entropy 계산을 위해서 decoder_input 패딩된 데이터와 실제 데이터를 골라내기 위한 mask 입니다.\n",
    "# getbatch 에서 받은 데이터를 주입할 placeholder\n",
    "target_weights = tf.placeholder(shape=(None, None), dtype=tf.float32, name=\"target_weights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_init\n",
    "\n",
    "seq2seq 모델에서 입력값과 출력값(예측값)을 담당하는 encoder와 decoder의 데이터 파이프라인을 정의합니다.\n",
    "placeholder 라는 구조는 lazy 하게 모델을 구성하고 차후에 데이터가 입력될 구조를 정의 합니다.\n",
    "\n",
    "![](http://i.imgur.com/Cc22Moi.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"embedding\") as scope:\n",
    "    #vocab_size * hidden_size 만큼의 크기를 가진 embedding_matrix를 생성 합니다.    \n",
    "    enc_embedding_matrix = tf.get_variable(\n",
    "        name=\"enc_embedding_matrix\",\n",
    "        shape=[vocab_size, enc_hidden_size],\n",
    "        initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        dtype=tf.float32)\n",
    "\n",
    "    dec_embedding_matrix = tf.get_variable(\n",
    "        name=\"dec_embedding_matrix\",\n",
    "        shape=[vocab_size, dec_hidden_size],\n",
    "        initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        dtype=tf.float32)\n",
    "\n",
    "    # 연속된 단어의 index값으로 표현된 입력값을 각 인덱스의 one-hot으로 표현하고 이어서\n",
    "    # embedding_vector화 하는 과정을 embedding_lookup을 통해서 쉽게 처리할 수 있습니다.\n",
    "\n",
    "    encoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "        enc_embedding_matrix, encoder_inputs2)\n",
    "\n",
    "    decoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "        dec_embedding_matrix, decoder_inputs2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## init_embeddings\n",
    "one-hot으로 표현된 단어 index를 hidden size * hidden_size 사이즈 만큼의 embedding vector로 생성 합니다.\n",
    "\n",
    "![](http://i.imgur.com/ZOj61li.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"encoder\") as scope:\n",
    "    # encoder_cell을 가지고 dynamic_rnn Layer를 생성하고\n",
    "    # embedding_lookup 통해서 만든 embedding_matrix를 연결합니다.\n",
    "    (encoder_outputs, encoder_state) = tf.nn.dynamic_rnn(cell=encoder_cell,\n",
    "                                                                inputs=encoder_inputs_embedded,\n",
    "                                                                sequence_length=encoder_inputs_length,\n",
    "                                                                time_major=True, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init_encoder\n",
    "\n",
    "encoder_cell을 가지고 dynamic_rnn을 통해서 Encoder 구조를 정의 합니다.\n",
    "\n",
    "![](http://i.imgur.com/AhmowtE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def _init_decoder(self, forward_only):\n",
    "with tf.variable_scope(\"decoder\") as scope:\n",
    "    def output_fn(outputs):\n",
    "        return tf.contrib.layers.linear(outputs, vocab_size, scope=scope)\n",
    "\n",
    "    # attention_states: size [batch_size, max_time, num_units]\n",
    "    attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "\n",
    "    #encoder_outputs 을 가지고 attention network에 필요한 값을 생성합니다.\n",
    "    (attention_keys, attention_values, attention_score_fn, attention_construct_fn) = (\n",
    "        seq2seq.prepare_attention(\n",
    "            attention_states=attention_states,\n",
    "            attention_option=\"bahdanau\",\n",
    "            num_units=dec_hidden_size))\n",
    "\n",
    "    #prediction 전용 모델인경우\n",
    "\n",
    "    #decoder 함수로 inference를 사용하고\n",
    "    #아래의 train 과정보다 더 많은 인자를 입력 받는데\n",
    "    #전처리 과정에서 진행한 embedding 과정의 역순을 일부 자동으로 처리하기 위함입니다.\n",
    "    decoder_fn = seq2seq.attention_decoder_fn_inference(\n",
    "        output_fn=output_fn,\n",
    "        encoder_state=encoder_state,\n",
    "        attention_keys=attention_keys,\n",
    "        attention_values=attention_values,\n",
    "        attention_score_fn=attention_score_fn,\n",
    "        attention_construct_fn=attention_construct_fn,\n",
    "        embeddings=dec_embedding_matrix,\n",
    "        start_of_sequence_id=model_config.GO_ID,\n",
    "        end_of_sequence_id=model_config.EOS_ID,\n",
    "        maximum_length=buckets[-1][1],\n",
    "        num_decoder_symbols=vocab_size,\n",
    "    )\n",
    "    # rnn_decoder Layer를 생성합니다\n",
    "    # encoder를 지나서 계산된 c는 decoder_fn의 인자를 통해 decoder에 연결되고\n",
    "    # decoder_outputs에서 logit 형태로 예측값을 출력합니다.\n",
    "    (decoder_outputs, decoder_state, decoder_context_state) = (\n",
    "        seq2seq.dynamic_rnn_decoder(\n",
    "            cell=decoder_cell,\n",
    "            decoder_fn=decoder_fn,\n",
    "            time_major=True,\n",
    "            scope=scope,\n",
    "        ))\n",
    "\n",
    "    decoder_logits = decoder_outputs\n",
    "\n",
    "    #vocab 사이즈 만큼의 각각 단어의 확률값으로 표현된 리스트의 순서열을 얻고\n",
    "    #argmax 연산을 통해서 최대값을 찾게 됩니다.\n",
    "    decoder_prediction = tf.argmax(decoder_logits, axis=-1, name='decoder_prediction')\n",
    "\n",
    "    #loss 계산을 위한 logit과 targets을 출력\n",
    "    logits = tf.transpose(decoder_logits, [1, 0, 2])\n",
    "    targets = tf.transpose(decoder_targets, [1, 0])\n",
    "\n",
    "    if not forward_only:\n",
    "        #train 모델인 경우 loss 값을 정의\n",
    "        seq_loss = seq2seq.sequence_loss(logits=logits, targets=targets,weights=target_weights)\n",
    "\n",
    "    #tensor sever를 정의하여 모델의 학습 과정에서 파라메터과 모델구조를 저장할 수 있도록 합니다.\n",
    "    saver = tf.train.Saver(tf.global_variables())        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init_decoder\n",
    "decoder_cell을 가지고 dynamic_rnn Layer를 생성하고 encoder 에서 나온 encoder_state를 연결합니다.  \n",
    "attention의 경우 encoder 단계에서의 각 단계의 state와 output에서 중간 단계의 값을 다시 decoder 구조에 연결합니다.  \n",
    "![](http://i.imgur.com/QRdjS8z.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(session, in_encoder_inputs, in_encoder_inputs_length):\n",
    "    #placeholder 로 정의한 데이터 파이프 라인에\n",
    "    #get_batch 등으로 모델 외부에서 주입할 데이터를 정의합니다.\n",
    "    input_feed = {\n",
    "        encoder_inputs: in_encoder_inputs,\n",
    "        encoder_inputs_length: in_encoder_inputs_length,\n",
    "    }\n",
    "    #학습 모델이 아니라면 출력에 필요한 OP 만 묶어서 계산하고\n",
    "    prediction = session.run(decoder_prediction, input_feed)\n",
    "    return prediction\n",
    "\n",
    "import re\n",
    "_WORD_SPLIT = re.compile(\"([.,!?\\\"':;)(])\")\n",
    "_DIGIT_RE = re.compile(r\"\\d{3,}\")\n",
    "def basic_tokenizer(sentence):\n",
    "  \"\"\"Very basic tokenizer: split the sentence into a list of tokens.\"\"\"\n",
    "  words = []\n",
    "  for space_separated_fragment in sentence.strip().split():\n",
    "    words.extend(re.split(_WORD_SPLIT, space_separated_fragment))\n",
    "  return [w.lower() for w in words if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from ./nn_models/model.ckpt-30500\n",
      "\n",
      "Input string : \n",
      "i ' ll keep it in mind \n",
      "\n",
      "Prediction Results : \n",
      "no . it ' s okay . i need it . . . one . . \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from lib import data_utils, model_utils\n",
    "from configs import model_config\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "\n",
    "#새로운 tensorflow 세션을 생성합니다 이후 sess 라는 이름으로 호출합니다\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    #체크 포인트 파일의 상태를 가져옵니다.\n",
    "    ckpt = tf.train.get_checkpoint_state(config.model_dir)\n",
    "\n",
    "    #이미 학습된 모델파일이 있다면 불러옵니다.\n",
    "    if ckpt and gfile.Exists(\"%s.index\" % ckpt.model_checkpoint_path):\n",
    "        print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    #forward_only 가 True 일떄 모델을 예측 전용의 모델을 생성합니다. 배치 사이즈가 1로 변경되고 모델 그래프에 옵티마이저가 제거 됩니다.\n",
    "    forward_only = True\n",
    "    config.batch_size = 1\n",
    "\n",
    "    #vacab파일의 경로를 정의합니다. 여러 모델의 테스트를 위해서 사전 크기를 파일명뒤에 명시적으로 표시합니다.\n",
    "    #예를들어 8000 사이즈의 vovab 파일은 vocab8000.in 입니다.\n",
    "    vocab_path = os.path.join(config.data_dir, 'vocab%d.in' % config.vocab_size)\n",
    "\n",
    "    #사전 파일을 로드합니다\n",
    "    #vovab.get(word) 형태로 해당 word에 맞는 사전 index 값을 반환합니다\n",
    "    #vovab.get(word) 값이 None 일경우 _UNK word로 취급합니다\n",
    "    #vocab_rev[index) 향태로 해당 index에 맞는 word를 반환 합니다.\n",
    "    vocab, vocab_rev = data_utils.load_vocabulary(vocab_path)\n",
    "    \n",
    "    #다음과 같은 형태도 가능하지만 문장부호의 처리를 위해서 basic_tokenizer를 이용합니다.\n",
    "    #s = \"Yeah Now's not a good time\".lower().split(\" \")\n",
    "       \n",
    "    #I'll keep it in mind.\n",
    "    #What the bell happened?\n",
    "    #I lost them, that's what happened.\n",
    "    #How did they get away?\n",
    "    #They ran. As fast as they could. Caught a train.\n",
    "    #Which one pulled the trigger?\n",
    "    #The Indian. I was about 30 yards away.\n",
    "        \n",
    "    s = \"I'll keep it in mind\"\n",
    "    s = basic_tokenizer(s)\n",
    "        \n",
    "    #잘라진 단어를 vocab.get() 을 이용해서 ids 값으로 변환합니다\n",
    "    inputs = []\n",
    "\n",
    "    for i in s:\n",
    "        #잘라진 소문자 단어로 사전에 인덱스를 구합니다.\n",
    "        index = vocab.get(i)\n",
    "        #index 가 None 라면 희귀한 UNK 단어입니다\n",
    "        if index == None:\n",
    "            #ids에 UNK_ID를 추가합니다\n",
    "            inputs.append([model_config.UNK_ID])\n",
    "        #index가 존재하는 단어라면\n",
    "        else:\n",
    "            #ids 값에 index를 추가합니다\n",
    "            inputs.append([index])\n",
    "\n",
    "    dev_inputs_length = [len(inputs)]\n",
    "\n",
    "    predicted = prediction(sess, inputs, dev_inputs_length)\n",
    "\n",
    "\n",
    "    print(\"\\nInput string : \")  \n",
    "    #입력한 문장을 ids2string 하여 출력합니다.\n",
    "    s = \"\"\n",
    "    for input in inputs:\n",
    "        s += (vocab_rev[input[0]]) + \" \"\n",
    "    print (s)\n",
    "\n",
    "    print(\"\\nPrediction Results : \")    \n",
    "    #입력한 문장에 대한 예측값(답변)을 ids2string 하여 출력합니다.\n",
    "    s = \"\"\n",
    "    for i in predicted:\n",
    "        s += (vocab_rev[i[0]]) + \" \"\n",
    "    print (s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
