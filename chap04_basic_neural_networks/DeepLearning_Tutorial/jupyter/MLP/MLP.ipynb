{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial - 4. MLP\n",
    "\n",
    "본 문서는 TensorFlow 를 사용하여 Deep Learning을 구현하기 위한 기초적인 실습 자료이다. 첫 번째 파트에서는 tensorflow에 대한 기본적인 설명과 deep learning 예제를 다루어보고, 두 번째 파트에서는 오픈소스를 활용한 Deep Reinforcement Learning 을 실습해보는 시간을 갖는다. 마지막으로는 TensorFlow로 구현되고 공개된 여러 오픈소스를 둘러본다.\n",
    "\n",
    "The code and comments are written by Dong-Hyun Kwak <imcomking@gmail.com>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "## [1. Tensorflow Intro](../TensorflowIntro/TensorflowIntro.ipynb)\n",
    "## [2. Basic](../Basic/Basic.ipynb)\n",
    "## [3. Gradient Descent](../GradientDescent/GradientDescent.ipynb)\n",
    "## [4. MLP](../MLP/MLP.ipynb)\n",
    "## [5. RNN](../RNN/RNN.ipynb)\n",
    "## [6. CNN](../CNN/CNN.ipynb)\n",
    "## [7. Reinforcemet Learning](../ReinforcemetLearning/ReinforcemetLearning.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  4. MLP\n",
    "<img src = \"tensorboard_mlp.png\">\n",
    "우선 기본적인 tf의 문법과 형식을 익히기 위해, 가장 기본적인 Deep Learning인 MLP 예제 코드를 실습해보자.\n",
    "\n",
    "### Multi-Layer Perceptron\n",
    "Multi-Layer Perceptron, 이하 MLP는 다음과 같은 구조를 가진 모델이다. Convolutional Neural Networks와 달리 굉장히 layer간의 연결이 빽빽하게 가득 차 있어, dense layer 혹은 fully connected layer라는 이름으로도 불리고 있다.\n",
    "\n",
    "\n",
    "<img src = \"mlp.png\">\n",
    "(출처: http://blog.refu.co/?p=931)\n",
    "tf를 이용해서 MNIST 데이터를 MLP로 분류하는 코드를 작성해보자.\n",
    "가장 먼저 사용할 라이브러리를 import 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "그리고 실습에서 사용할 MNIST 데이터를 다음과 같이 다운로드 받는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# download the mnist data.\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "    OOOOOOOOOOOOOO          \n",
      "  OOOOOOOOOOOOOOOOO         \n",
      "  OOOOOOOO     OOOOO        \n",
      "                 OOO        \n",
      "                  OOO       \n",
      "                  OOO       \n",
      "                 OOOO       \n",
      "             OOOOOOOOO      \n",
      "           OOOOOOOOOOO      \n",
      "        OOOOOOOO  OOO       \n",
      "       OOOO       OOO       \n",
      "      OOO         OOO       \n",
      "                  OOO       \n",
      "                 OOO        \n",
      "                OOOO        \n",
      "                OOO         \n",
      "                OO          \n",
      "               OOO          \n",
      "                            \n",
      "                            \n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "              OOOOO         \n",
      "            OOOOOOOO        \n",
      "           OOOOOOOOOO       \n",
      "          OOOOO    OO       \n",
      "          OOOO O   OO       \n",
      "               O   OO       \n",
      "               O  OOO       \n",
      "               OOOOO        \n",
      "           OOOOOOOO         \n",
      "           OOOOOOO          \n",
      "            OOOOO           \n",
      "               OOO          \n",
      "                OO          \n",
      "      OO         OO         \n",
      "     OO         OOO         \n",
      "     OO        OOO          \n",
      "     OO      OOOOO          \n",
      "     OOOOOOOOOOOO           \n",
      "      OOOOOOOOO             \n",
      "       OOOOOO               \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "           OOOO             \n",
      "          OOOO              \n",
      "          OOO      OO       \n",
      "         OOO       OO       \n",
      "        OOO       OOO       \n",
      "        OOO       OOO       \n",
      "        OOO  OOOOOOO        \n",
      "         OOOOOOOOOOO        \n",
      "         OOOOO OOOO         \n",
      "                OOO         \n",
      "                OO          \n",
      "                OO          \n",
      "               OOO          \n",
      "               OO           \n",
      "               OO           \n",
      "              OOO           \n",
      "              OOO           \n",
      "              OOO           \n",
      "              OOO           \n",
      "               OO           \n",
      "                            \n",
      "                            \n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                OO          \n",
      "               OOO          \n",
      "              OOOO          \n",
      "             OOOO           \n",
      "            OOOO            \n",
      "           OOOO             \n",
      "           OOO              \n",
      "          OOO               \n",
      "          OO                \n",
      "          OO                \n",
      "         OO                 \n",
      "         OO       OO        \n",
      "         OO     OOOOO       \n",
      "         OO    OOOOOO       \n",
      "         OO   OOOOOOO       \n",
      "         OOOOOOOOOOO        \n",
      "          OOOOOOOOO         \n",
      "          OOOOOOO           \n",
      "          OOO               \n",
      "          O                 \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "              OO            \n",
      "               O            \n",
      "               OO           \n",
      "               OO           \n",
      "              OO            \n",
      "              OO            \n",
      "              OO            \n",
      "             OOO            \n",
      "             OOO            \n",
      "             OOO            \n",
      "             OOO            \n",
      "             OO             \n",
      "             OO             \n",
      "            OOO             \n",
      "            OOO             \n",
      "            OOO             \n",
      "           OOO              \n",
      "           OOO              \n",
      "           OO               \n",
      "           OO               \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                OOOOO       \n",
      "              OOOOOOOOO     \n",
      "             OOOOOOOOOO     \n",
      "            OOOOO   OOO     \n",
      "            OOO     OOO     \n",
      "           OOO      OO      \n",
      "           OO     OOOO      \n",
      "           OO    OOOO       \n",
      "           OOOOOOOOO        \n",
      "            OOOOOO          \n",
      "           OOOOOOO          \n",
      "         OOOOOOOOO          \n",
      "        OOOOO    OO         \n",
      "       OOOO      OO         \n",
      "       OO        OO         \n",
      "       OO       OOO         \n",
      "       OOO     OOOO         \n",
      "        OOOOOOOOOO          \n",
      "        OOOOOOOO            \n",
      "          OOOO              \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                O           \n",
      "               OO           \n",
      "               OO           \n",
      "              OOO           \n",
      "              OOO           \n",
      "              OOO           \n",
      "              OOO           \n",
      "             OOOO           \n",
      "             OOO            \n",
      "             OOO            \n",
      "             OOO            \n",
      "            OOOO            \n",
      "            OOO             \n",
      "            OOO             \n",
      "           OOOO             \n",
      "           OOO              \n",
      "           OOO              \n",
      "           OOOOO            \n",
      "           OOOO             \n",
      "            OO              \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "              OOO           \n",
      "             OOOO           \n",
      "            OOOOO  OO       \n",
      "           OOOOO   OOO      \n",
      "          OOOOO    OOOOO    \n",
      "          OOOO     OOOO     \n",
      "         OOOO       OOO     \n",
      "        OOOO        OOO     \n",
      "       OOOO         OOO     \n",
      "      OOOO         OOOO     \n",
      "      OOOO         OOOO     \n",
      "      OOO          OOO      \n",
      "      OO          OOOO      \n",
      "      OO          OOO       \n",
      "      OOO        OOOO       \n",
      "      OOO      OOOOO        \n",
      "      OOOOOOOOOOOOOO        \n",
      "       OOOOOOOOOOO          \n",
      "       OOOOOOOOO            \n",
      "          OO                \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "             OOO            \n",
      "            OO OO           \n",
      "          OOO               \n",
      "         OOO     OO         \n",
      "        OOO      OO         \n",
      "        OO       OO         \n",
      "       OO       OOO         \n",
      "       OO      OOOO         \n",
      "       OO   OOOOOOO         \n",
      "       OOOOOOO   O          \n",
      "         OOO     OO         \n",
      "                 OO         \n",
      "                 OO         \n",
      "                 O          \n",
      "                 O          \n",
      "                 O          \n",
      "                 O          \n",
      "                 O          \n",
      "                 O          \n",
      "                 O          \n",
      "                            \n",
      "                            \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "              OOOO          \n",
      "            OOOOOOO   O     \n",
      "           OOOOOOOOO  O     \n",
      "          OOOO    OO  O     \n",
      "          OOO      O        \n",
      "          OOO      O        \n",
      "          OOO     OOO       \n",
      "           OOO  OOOOO       \n",
      "            OOOOOOOOO O     \n",
      "           OOOOOOO    O     \n",
      "          OOOOOO      O     \n",
      "         OOOOOOO      O     \n",
      "        OOO   OOO           \n",
      "       OOO     OO           \n",
      "       OO       OO          \n",
      "       OO       OO          \n",
      "       OOO      OO          \n",
      "        OOOO   OOO    O     \n",
      "        OOOOOOOOOO    O     \n",
      "         OOOOOOO            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for k in range(10):\n",
    "    print (mnist.train.labels[k])\n",
    "    img = mnist.train.images[k]\n",
    "    for i in range(28):\n",
    "        l = \"\"\n",
    "        for j in range(28):\n",
    "            if img[i*28+j] > 0.5:\n",
    "                l = l+\"O\"\n",
    "            else:\n",
    "                l = l+\" \"\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 mnist 데이터를 저장시킬 x와 y_target 변수를 선언해야한다.\n",
    "tf.placeholder는 우리가 원하는 데이터를 Computation Graph에 입력시켜주는 역할을 하는 변수이다. 즉 input 을 받기 위한 변수라고 생각할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder is used for feeding data.\n",
    "x = tf.placeholder(\"float\", shape=[None, 784]) # none represents variable length of dimension. 784 is the dimension of MNIST data.\n",
    "y_target = tf.placeholder(\"float\", shape=[None, 10]) # shape argument is optional, but this is useful to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 넣을 변수를 생성했으니, 이제 실제 Neural Network에서 사용할 변수들을 생성하고, 이들을 이용해 Computation Graph를 그려본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all the variables are allocated in GPU memory\n",
    "W1 = tf.Variable(tf.zeros([784, 256]))      # create (784 * 256) matrix\n",
    "b1 = tf.Variable(tf.zeros([256]))           # create (1 * 256) vector\n",
    "weighted_summation1 = tf.matmul(x, W1) + b1 # compute --> weighted summation\n",
    "h1 = tf.sigmoid( weighted_summation1 )      # compute --> sigmoid(weighted summation)\n",
    "\n",
    "# Repeat again\n",
    "W2 = tf.Variable(tf.zeros([256, 10]))        # create (256 * 10) matrix\n",
    "b2 = tf.Variable(tf.zeros([10]))             # create (1 * 10) vector\n",
    "weighted_summation2 = tf.matmul(h1, W2) + b2 # compute --> weighted summation\n",
    "y = tf.nn.softmax(weighted_summation2)       # compute classification --> softmax(weighted summation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 과정까지 완료된 경우, 변수 y는 3층짜리 Neural Network(MLP)의 연산 결과가 저장되도록 되어있다. 이제 이 MLP를 학습하고 실행시켜보자.\n",
    "\n",
    "먼저 tf에는 Session이라는 개념이 있다. 이는 간단히 말해 하나의 Computation Graph가 실행되기 위한 계산 단위를 의미한다. 즉 하나의 session에는 보통 하나의 graph가 담겨있다. 이를 생성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-b316e46f7de6>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True))) # open a session which is a envrionment of computation graph.\n",
    "sess.run(tf.initialize_all_variables())# initialize the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 tf.initialize_all_variables() 는 앞서 생성했던 변수들을 사용하기 위해서 반드시 실행해야하는 초기화 단계이다. 이 연산은 session에 의해서 실행되므로, 이와 같이 sess.run() 함수를 이용해 실행시켜준다.\n",
    "\n",
    "이제 MLP를 학습시키기 위한 미분 계산과 같은 수학적인 연산들을 정의해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the Loss function\n",
    "cross_entropy = -tf.reduce_sum(y_target*tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entorpy는 MLP의 분류 모델에서 사용하는 에러함수이다. 간단히 말해 이 cross entropy는 MLP가 예측한 y 값이 실제 데이터와 다른 정도를 확률적으로 측정한다고 생각해볼 수 있다.\n",
    "\n",
    "MLP가 학습 되기위해서는 이 에러함수가 최대한 작은 값을 내도록 만들어야한다. 그래서 이 에러함수를 각각의 변수들로 편미분하여 gradient를 계산하고, 에러가 최소가 되는 변수값을 찾아가는 것이 바로 MLP의 학습 알고리즘이다.\n",
    "\n",
    "이를 구현하려면 원래 미분 후 에러가 줄어드는 방향으로 변수를 이동시키는 과정등을 직접 코딩해야하지만, 자동 미분을 제공하는 tf에서는 단 한줄로 구현할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define optimization algorithm\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 학습 알고리즘의 구현이 끝났고, MLP가 잘 학습하고 있는지 성능을 측정하기 위한 정확도 계산을 정의해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_target, 1))\n",
    "# correct_prediction is list of boolean which is the result of comparing(model prediction , data)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) \n",
    "# tf.cast() : changes true -> 1 / false -> 0\n",
    "# tf.reduce_mean() : calculate the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct_prediction 는 뭔가 수식이 복잡해 보이지만 사실 매우 간단한 계산이다. tf.argmax()는 y 벡터 중에서 가장 값이 큰 index를 알려주는 함수이다. 즉 모델이 예측한 class, y와 실제 데이터에 labeling된 y_target을 비교하여 같으면 true, 다르면 false를 내도록 계산한 것이다.\n",
    "\n",
    "그리고 accuracy는 앞서 계산한 true/false 리스트를 1과 0으로 변환한 뒤, 이를 평균낸 것이다.\n",
    "\n",
    "자 그러면 이제 필요한 모든 Computation Graph를 정의하였다. 이제 이를 session을 이용하여 실행만 시키면 된다.\n",
    "\n",
    "\n",
    "우선은 Ctrl + Enter를 눌러 다음 코드를 실행 시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy: 0.140\n",
      "step 500, training accuracy: 0.390\n",
      "step 1000, training accuracy: 0.530\n",
      "step 1500, training accuracy: 0.760\n",
      "step 2000, training accuracy: 0.890\n",
      "step 2500, training accuracy: 0.900\n",
      "step 3000, training accuracy: 0.870\n",
      "step 3500, training accuracy: 0.930\n",
      "step 4000, training accuracy: 0.930\n",
      "step 4500, training accuracy: 0.940\n",
      "step 5000, training accuracy: 0.910\n",
      "test accuracy: 0.905\n"
     ]
    }
   ],
   "source": [
    "# training the MLP\n",
    "for i in range(5001): # minibatch iteraction\n",
    "    batch = mnist.train.next_batch(100) # minibatch size\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_target: batch[1]}) # feed data into placeholder x, y_target\n",
    "\n",
    "    if i%500 == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x:batch[0], y_target: batch[1]})\n",
    "        print (\"step %d, training accuracy: %.3f\"%(i, train_accuracy))\n",
    "\n",
    "# for given x, y_target data set\n",
    "print  (\"test accuracy: %g\"% sess.run(accuracy, feed_dict={x: mnist.test.images, y_target: mnist.test.labels}))\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 5000번의 minibatch iteraction을 실행하고, 500번 마다 학습 정확도를 측정, 그리고 마지막에는 테스트 정확도를 측정하고 있다.\n",
    "\n",
    "코드는 간단한 구조이다. for 문이 전체 iteration을 실행하고, 맨 처음 가져왔던 mnist 데이터를 100개씩 가져와서 place_holder에 넣어준다. 그리고 sess.run()을 통해 위에서 정의했던 학습 알고리즘과 정확도 계산을 실행시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리가 만든 MLP의 구조를 직접 눈으로 확인해보자.\n",
    "\n",
    "이제 우리가 만든 MLP의 구조를 직접 눈으로 확인해보자.\n",
    "\n",
    "### TensorBoard 설정하기\n",
    "TensorFlow는 TensorBoard라는 매우 강력한 visualization tool을 제공한다. 이를 사용하면 웹브라우저 형태로 사용자가 모델의 구조를 눈으로 확인하고, 파라미터 값의 변화를 살펴보는 등의 직관적인 분석이 가능하다.\n",
    "\n",
    "이를 활용해 방금 만들었던 MLP를 분석해보자. 그러려면 다음의 사항을 반영해 코드를 수정하여야 한다.\n",
    "\n",
    "* **변수들의 이름 지어주기**\n",
    "\n",
    "* **변수들의 Summary 생성**\n",
    "\n",
    "* **변수들의 Summary 기록**\n",
    "\n",
    "아래의 코드는 위의 3가지 사항을 모두 반영하고, MLP 코드를 하나의 함수로 정리한 코드이다. 세세한 차이는 위에서 우리가 짰던 코드와 비교를 하면 파악이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy: 0.140\n",
      "step 500, training accuracy: 0.360\n",
      "step 1000, training accuracy: 0.340\n",
      "step 1500, training accuracy: 0.430\n",
      "step 2000, training accuracy: 0.330\n",
      "step 2500, training accuracy: 0.370\n",
      "step 3000, training accuracy: 0.310\n",
      "step 3500, training accuracy: 0.350\n",
      "step 4000, training accuracy: 0.380\n",
      "step 4500, training accuracy: 0.350\n",
      "step 5000, training accuracy: 0.380\n",
      "test accuracy: 0.3819\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def MLP():\n",
    "    # download the mnist data.\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True) \n",
    "\n",
    "\n",
    "    # placeholder is used for feeding data.\n",
    "    x = tf.placeholder(\"float\", shape=[None, 784], name = 'x') # none represents variable length of dimension. 784 is the dimension of MNIST data.\n",
    "    y_target = tf.placeholder(\"float\", shape=[None, 10], name = 'y_target') # shape argument is optional, but this is useful to debug.\n",
    "\n",
    "\n",
    "    # all the variables are allocated in GPU memory\n",
    "    W1 = tf.Variable(tf.zeros([784, 256]), name = 'W1')   # create (784 * 256) matrix\n",
    "    b1 = tf.Variable(tf.zeros([256]), name = 'b1')        # create (1 * 256) vector\n",
    "    h1 = tf.sigmoid(tf.matmul(x, W1) + b1, name = 'h1')   # compute --> sigmoid(weighted summation)\n",
    "\n",
    "    # Repeat again\n",
    "    W2 = tf.Variable(tf.zeros([256, 10]), name = 'W2')     # create (256 * 10) matrix\n",
    "    b2 = tf.Variable(tf.zeros([10]), name = 'b2')          # create (1 * 10) vector\n",
    "    y = tf.nn.softmax(tf.matmul(h1, W2) + b2, name = 'y')  # compute classification --> softmax(weighted summation)\n",
    "\n",
    "\n",
    "    # define the Loss function\n",
    "    cross_entropy = -tf.reduce_sum(y_target*tf.log(y), name = 'cross_entropy')\n",
    "\n",
    "\n",
    "    # define optimization algorithm\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_target, 1))\n",
    "    # correct_prediction is list of boolean which is the result of comparing(model prediction , data)\n",
    "\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) \n",
    "    # tf.cast() : changes true -> 1 / false -> 0\n",
    "    # tf.reduce_mean() : calculate the mean\n",
    "\n",
    "\n",
    "\n",
    "    # create summary of parameters\n",
    "    tf.summary.histogram('weights_1', W1)\n",
    "    tf.summary.histogram('weights_2', W2)\n",
    "    tf.summary.histogram('y', y)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    # Create Session\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) # open a session which is a envrionment of computation graph.\n",
    "    sess.run(tf.global_variables_initializer())# initialize the variables\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(\"/tmp/mlp\",sess.graph)\n",
    "\n",
    "    # training the MLP\n",
    "    for i in range(5001): # minibatch iteraction\n",
    "        batch = mnist.train.next_batch(100) # minibatch size\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y_target: batch[1]}) # placeholder's none length is replaced by i:i+100 indexes\n",
    "\n",
    "        if i%500 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x:batch[0], y_target: batch[1]})\n",
    "            print (\"step %d, training accuracy: %.3f\"%(i, train_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "            # calculate the summary and write.\n",
    "            summary = sess.run(merged, feed_dict={x:batch[0], y_target: batch[1]})\n",
    "            summary_writer.add_summary(summary , i)\n",
    "\n",
    "    # for given x, y_target data set\n",
    "    print  (\"test accuracy: %g\"% sess.run(accuracy, feed_dict={x: mnist.test.images, y_target: mnist.test.labels}))\n",
    "    sess.close()\n",
    "\n",
    "MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard 실행하기\n",
    "위와 같이 코드를 수정했다면, 이제 리눅스 shell로 이동한 후, tensorboard를 실행시킨다.\n",
    "혹은 IPython에서 new -> terminal을 클릭하여 아래의 명령을 실행할 수도 있다.\n",
    "\n",
    "\n",
    "tensorboard --logdir=/tmp/mlp --port=6006\n",
    "\n",
    "\n",
    "(만약 위 명령어 실행시 문제가 생기는 경우 다음을 실행)\n",
    "<br>cd tensorflow/tensorflow/tensorboard\n",
    "<br>python tensorboard.py --logdir=/tmp/mlp --port=6006\n",
    "\n",
    "\n",
    "그다음 [IP]:6006/#graphs 에 접속하면 아래와 같은 그림을 볼 수 있다.\n",
    "<br>(ex) http://192.168.99.100:6006/#graphs\n",
    "\n",
    "<img src = \"mlp_total.png\">\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf1.1]",
   "language": "python",
   "name": "conda-env-tf1.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
